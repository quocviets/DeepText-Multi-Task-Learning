import pandas as pd
import numpy as np
import json
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import os

# ============================================
# PHáº¦N 1: Táº O TRAINING_LOG.CSV Tá»ª HISTORY.JSON
# ============================================
print("=" * 60)
print("PHáº¦N 1: Táº¡o training_log.csv tá»« history.json")
print("=" * 60)

# Äá»c file history JSON
history_path = "models/history_20251027_085402.json"
with open(history_path, 'r') as f:
    history_data = json.load(f)

# Táº¡o DataFrame tá»« history
history_df = pd.DataFrame(history_data)

# ThÃªm cá»™t epoch (báº¯t Ä‘áº§u tá»« 1)
history_df.insert(0, 'epoch', range(1, len(history_df) + 1))

# LÆ°u ra training_log.csv
training_log_path = "models/training_log.csv"
history_df.to_csv(training_log_path, index=False)
print(f"âœ… ÄÃ£ táº¡o file: {training_log_path}")
print(f"   Sá»‘ epochs: {len(history_df)}")
print(f"   CÃ¡c cá»™t: {', '.join(history_df.columns)}")
print()

# ============================================
# PHáº¦N 2: LOAD MODEL VÃ€ Táº O PREDICTIONS
# ============================================
print("=" * 60)
print("PHáº¦N 2: Load model vÃ  táº¡o predictions")
print("=" * 60)

# Load model Ä‘Ã£ train
model_path = "models/best_model_20251027_085402.h5"
print(f"ğŸ“¦ Äang load model tá»«: {model_path}")
model = load_model(model_path)
print("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c load thÃ nh cÃ´ng!")
print(f"   Model inputs: {model.input_shape}")
print(f"   Model outputs: {[output.shape for output in model.outputs]}")
print()

# Äá»c dá»¯ liá»‡u validation (sá»­ dá»¥ng lÃ m test set)
print("ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u validation...")
val_df = pd.read_csv("val_clean.csv", sep=';')
print(f"âœ… ÄÃ£ Ä‘á»c {len(val_df)} máº«u tá»« val_clean.csv")
print()

# Chuáº©n bá»‹ text data
texts = val_df['text'].astype(str).values

# Tokenize vÃ  padding (pháº£i match vá»›i training)
print("ğŸ”¤ Äang tokenize vÃ  padding text...")
# Äá»c toÃ n bá»™ train data Ä‘á»ƒ fit tokenizer giá»‘ng nhÆ° khi train
train_df = pd.read_csv("train_clean.csv", sep=';')
all_texts = train_df['text'].astype(str).values

# Táº¡o tokenizer
max_words = 10000
max_len = 100

tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')
tokenizer.fit_on_texts(all_texts)

# Transform validation texts
sequences = tokenizer.texts_to_sequences(texts)
X_val = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')
print(f"âœ… Text Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½: shape = {X_val.shape}")
print()

# Predict
print("ğŸ”® Äang thá»±c hiá»‡n prediction...")
predictions = model.predict(X_val, batch_size=128, verbose=1)
print()

# ============================================
# PHáº¦N 3: Xá»¬ LÃ VÃ€ LÆ¯U PREDICTIONS
# ============================================
print("=" * 60)
print("PHáº¦N 3: Xá»­ lÃ½ vÃ  lÆ°u predictions")
print("=" * 60)

# Model cÃ³ 3 outputs: emotion (7 classes), hate (3 classes), violence (3 classes)
emotion_pred = predictions[0]  # (samples, 7)
hate_pred = predictions[1]     # (samples, 3)
violence_pred = predictions[2] # (samples, 3)

print(f"Emotion predictions shape: {emotion_pred.shape}")
print(f"Hate predictions shape: {hate_pred.shape}")
print(f"Violence predictions shape: {violence_pred.shape}")
print()

# Táº¡o DataFrame káº¿t quáº£
result_df = pd.DataFrame()
result_df['text'] = texts

# ThÃªm emotion predictions (7 cá»™t: sad, joy, love, angry, fear, surprise, no_emo)
emotion_labels = ['sad', 'joy', 'love', 'angry', 'fear', 'surprise', 'no_emo']
for i, label in enumerate(emotion_labels):
    result_df[f'pred_{label}'] = emotion_pred[:, i]
    result_df[f'pred_{label}_binary'] = (emotion_pred[:, i] > 0.5).astype(int)

# ThÃªm hate predictions (3 cá»™t: hate, offensive, neutral)
hate_labels = ['hate', 'offensive', 'neutral']
for i, label in enumerate(hate_labels):
    result_df[f'pred_{label}'] = hate_pred[:, i]
    result_df[f'pred_{label}_binary'] = (hate_pred[:, i] > 0.5).astype(int)

# ThÃªm violence predictions (3 cá»™t: sex_viol, phys_viol, no_viol)
violence_labels = ['sex_viol', 'phys_viol', 'no_viol']
for i, label in enumerate(violence_labels):
    result_df[f'pred_{label}'] = violence_pred[:, i]
    result_df[f'pred_{label}_binary'] = (violence_pred[:, i] > 0.5).astype(int)

# ThÃªm ground truth labels (náº¿u cÃ³)
for label in emotion_labels + hate_labels + violence_labels:
    if label in val_df.columns:
        result_df[f'true_{label}'] = val_df[label].values

# LÆ°u file predictions
predictions_path = "predictions_sentiment.csv"
result_df.to_csv(predictions_path, index=False, encoding='utf-8-sig')
print(f"âœ… ÄÃ£ lÆ°u predictions: {predictions_path}")
print(f"   Sá»‘ máº«u: {len(result_df)}")
print(f"   Sá»‘ cá»™t: {len(result_df.columns)}")
print()

# In thá»‘ng kÃª
print("ğŸ“Š Thá»‘ng kÃª predictions:")
print("-" * 60)

# Emotion statistics
print("\nğŸ­ Emotion Predictions:")
for label in emotion_labels:
    count = result_df[f'pred_{label}_binary'].sum()
    percentage = (count / len(result_df)) * 100
    print(f"  {label:12s}: {count:6d} samples ({percentage:5.2f}%)")

# Hate statistics
print("\nğŸ’¢ Hate Predictions:")
for label in hate_labels:
    count = result_df[f'pred_{label}_binary'].sum()
    percentage = (count / len(result_df)) * 100
    print(f"  {label:12s}: {count:6d} samples ({percentage:5.2f}%)")

# Violence statistics
print("\nâš ï¸  Violence Predictions:")
for label in violence_labels:
    count = result_df[f'pred_{label}_binary'].sum()
    percentage = (count / len(result_df)) * 100
    print(f"  {label:12s}: {count:6d} samples ({percentage:5.2f}%)")

print()
print("=" * 60)
print("âœ… HOÃ€N THÃ€NH Táº¤T Cáº¢!")
print("=" * 60)
print(f"\nCÃ¡c file Ä‘Ã£ táº¡o:")
print(f"  1. {training_log_path}")
print(f"  2. {predictions_path}")
print()
print("ğŸ“ Báº¡n cÃ³ thá»ƒ:")
print("  - Xem training history: pd.read_csv('models/training_log.csv')")
print("  - Xem predictions: pd.read_csv('predictions_sentiment.csv')")
print("  - Load model Ä‘á»ƒ predict thÃªm: model = load_model('models/best_model_20251027_085402.h5')")


