import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import tensorflow as tf

# ============================================
# LOAD MODEL Vá»šI CUSTOM OBJECTS
# ============================================
print("=" * 60)
print("Load model vÃ  táº¡o predictions")
print("=" * 60)

# ÄÄƒng kÃ½ custom objects Ä‘á»ƒ load model
@tf.keras.utils.register_keras_serializable()
class Cast(tf.keras.layers.Layer):
    def __init__(self, dtype='float32', **kwargs):
        super(Cast, self).__init__(**kwargs)
        self.target_dtype = dtype
    
    def call(self, inputs):
        return tf.cast(inputs, self.target_dtype)
    
    def get_config(self):
        config = super(Cast, self).get_config()
        config.update({'dtype': self.target_dtype})
        return config

# Load model vá»›i custom objects
model_path = "models/best_model_20251027_085402.h5"
print(f"ğŸ“¦ Äang load model tá»«: {model_path}")

try:
    custom_objects = {'Cast': Cast}
    model = load_model(model_path, custom_objects=custom_objects, compile=False)
    print("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c load thÃ nh cÃ´ng!")
    print(f"   Model inputs: {model.input_shape}")
    if isinstance(model.output, list):
        print(f"   Model outputs: {len(model.outputs)} outputs")
        for i, out in enumerate(model.outputs):
            print(f"      Output {i+1}: {out.shape}")
    else:
        print(f"   Model output: {model.output.shape}")
    print()
except Exception as e:
    print(f"âŒ Lá»—i khi load model: {e}")
    print("\nâš ï¸ Thá»­ phÆ°Æ¡ng phÃ¡p khÃ¡c...")
    
    # Thá»­ load vá»›i compile=False vÃ  safe_mode=False
    try:
        model = tf.keras.models.load_model(
            model_path, 
            custom_objects={'Cast': Cast},
            compile=False,
            safe_mode=False
        )
        print("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c load thÃ nh cÃ´ng (safe_mode=False)!")
    except Exception as e2:
        print(f"âŒ Váº«n khÃ´ng load Ä‘Æ°á»£c: {e2}")
        print("\nğŸ’¡ Gá»£i Ã½:")
        print("  - Model cÃ³ thá»ƒ cáº§n cÃ¡c custom layers khÃ¡c")
        print("  - Hoáº·c cáº§n rebuild model vá»›i code training gá»‘c")
        exit(1)

# ============================================
# Äá»ŒC VÃ€ Xá»¬ LÃ Dá»® LIá»†U
# ============================================
print("ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u validation/test...")
val_df = pd.read_csv("val_clean.csv", sep=';')
print(f"âœ… ÄÃ£ Ä‘á»c {len(val_df)} máº«u tá»« val_clean.csv")
print()

# Chuáº©n bá»‹ text data
texts = val_df['text'].astype(str).values

# Tokenize vÃ  padding (pháº£i match vá»›i training)
print("ğŸ”¤ Äang tokenize vÃ  padding text...")
train_df = pd.read_csv("train_clean.csv", sep=';')
all_texts = train_df['text'].astype(str).values

# Táº¡o tokenizer vá»›i cáº¥u hÃ¬nh thÃ´ng dá»¥ng
max_words = 10000
max_len = 100

tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')
tokenizer.fit_on_texts(all_texts)

# Transform validation texts
sequences = tokenizer.texts_to_sequences(texts)
X_val = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')
print(f"âœ… Text Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½: shape = {X_val.shape}")
print()

# ============================================
# PREDICT
# ============================================
print("ğŸ”® Äang thá»±c hiá»‡n prediction...")
try:
    predictions = model.predict(X_val, batch_size=128, verbose=1)
    print("âœ… Prediction hoÃ n thÃ nh!")
    print()
except Exception as e:
    print(f"âŒ Lá»—i khi predict: {e}")
    exit(1)

# ============================================
# Xá»¬ LÃ VÃ€ LÆ¯U PREDICTIONS
# ============================================
print("=" * 60)
print("Xá»­ lÃ½ vÃ  lÆ°u predictions")
print("=" * 60)

# Kiá»ƒm tra sá»‘ outputs
if isinstance(predictions, list):
    print(f"Model cÃ³ {len(predictions)} outputs")
    for i, pred in enumerate(predictions):
        print(f"  Output {i+1}: {pred.shape}")
else:
    print(f"Model cÃ³ 1 output: {predictions.shape}")
    predictions = [predictions]

# Giáº£ Ä‘á»‹nh: Output 1 = emotion, Output 2 = hate, Output 3 = violence
emotion_pred = predictions[0]
hate_pred = predictions[1] if len(predictions) > 1 else None
violence_pred = predictions[2] if len(predictions) > 2 else None

# Táº¡o DataFrame káº¿t quáº£
result_df = pd.DataFrame()
result_df['text'] = texts

# Labels
emotion_labels = ['sad', 'joy', 'love', 'angry', 'fear', 'surprise', 'no_emo']
hate_labels = ['hate', 'offensive', 'neutral']
violence_labels = ['sex_viol', 'phys_viol', 'no_viol']

# ThÃªm emotion predictions
print(f"\nğŸ­ Xá»­ lÃ½ Emotion predictions ({emotion_pred.shape})...")
for i, label in enumerate(emotion_labels[:emotion_pred.shape[1]]):
    result_df[f'pred_{label}'] = emotion_pred[:, i]
    result_df[f'pred_{label}_binary'] = (emotion_pred[:, i] > 0.5).astype(int)

# ThÃªm hate predictions
if hate_pred is not None:
    print(f"ğŸ’¢ Xá»­ lÃ½ Hate predictions ({hate_pred.shape})...")
    for i, label in enumerate(hate_labels[:hate_pred.shape[1]]):
        result_df[f'pred_{label}'] = hate_pred[:, i]
        result_df[f'pred_{label}_binary'] = (hate_pred[:, i] > 0.5).astype(int)

# ThÃªm violence predictions
if violence_pred is not None:
    print(f"âš ï¸  Xá»­ lÃ½ Violence predictions ({violence_pred.shape})...")
    for i, label in enumerate(violence_labels[:violence_pred.shape[1]]):
        result_df[f'pred_{label}'] = violence_pred[:, i]
        result_df[f'pred_{label}_binary'] = (violence_pred[:, i] > 0.5).astype(int)

# ThÃªm ground truth labels
all_labels = emotion_labels + hate_labels + violence_labels
for label in all_labels:
    if label in val_df.columns:
        result_df[f'true_{label}'] = val_df[label].values

# LÆ°u file predictions
predictions_path = "predictions_sentiment.csv"
result_df.to_csv(predictions_path, index=False, encoding='utf-8-sig')
print(f"\nâœ… ÄÃ£ lÆ°u predictions: {predictions_path}")
print(f"   Sá»‘ máº«u: {len(result_df)}")
print(f"   Sá»‘ cá»™t: {len(result_df.columns)}")

# In thá»‘ng kÃª
print("\nğŸ“Š Thá»‘ng kÃª predictions:")
print("-" * 60)

# Emotion statistics
print("\nğŸ­ Emotion Predictions:")
for label in emotion_labels:
    if f'pred_{label}_binary' in result_df.columns:
        count = result_df[f'pred_{label}_binary'].sum()
        percentage = (count / len(result_df)) * 100
        avg_prob = result_df[f'pred_{label}'].mean()
        print(f"  {label:12s}: {count:6d} samples ({percentage:5.2f}%) - avg prob: {avg_prob:.4f}")

# Hate statistics
if hate_pred is not None:
    print("\nğŸ’¢ Hate Predictions:")
    for label in hate_labels:
        if f'pred_{label}_binary' in result_df.columns:
            count = result_df[f'pred_{label}_binary'].sum()
            percentage = (count / len(result_df)) * 100
            avg_prob = result_df[f'pred_{label}'].mean()
            print(f"  {label:12s}: {count:6d} samples ({percentage:5.2f}%) - avg prob: {avg_prob:.4f}")

# Violence statistics
if violence_pred is not None:
    print("\nâš ï¸  Violence Predictions:")
    for label in violence_labels:
        if f'pred_{label}_binary' in result_df.columns:
            count = result_df[f'pred_{label}_binary'].sum()
            percentage = (count / len(result_df)) * 100
            avg_prob = result_df[f'pred_{label}'].mean()
            print(f"  {label:12s}: {count:6d} samples ({percentage:5.2f}%) - avg prob: {avg_prob:.4f}")

print()
print("=" * 60)
print("âœ… HOÃ€N THÃ€NH!")
print("=" * 60)


