# DeepText Multi-Task Learning System

A comprehensive deep learning system for multi-task text classification, supporting emotion detection, hate speech detection, and violence detection in Vietnamese text.

## ğŸš€ Features

- **Multi-Task Learning**: Simultaneously classify emotion, hate speech, and violence
- **Advanced Architecture**: Shared embedding + BiLSTM + attention mechanism
- **Optimized Training**: Batch normalization, class weighting, and advanced callbacks
- **Comprehensive Evaluation**: Detailed metrics, confusion matrices, and visualizations
- **Production Ready**: Complete pipeline from data preprocessing to model deployment
- **Modular Design**: Clean, extensible codebase with proper separation of concerns

## ğŸ“ Project Structure

```
DeepText-MTL/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ train_dataset.csv                # Original dataset
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train.pkl                        # Preprocessed data
â”‚       â”œâ”€â”€ val.pkl
â”‚       â””â”€â”€ test.pkl
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb            # EDA & statistics
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb               # Data cleaning & encoding
â”‚   â””â”€â”€ 03_train_experiments.ipynb           # Hyperparameter tuning
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing/
â”‚   â”‚   â””â”€â”€ preprocess_text.py               # Text preprocessing utilities
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ deeptext_multitask.py            # Basic model implementation
â”‚   â”‚   â””â”€â”€ multi_task_model_optimized.py    # Optimized model with attention
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train.py                         # Training pipeline
â”‚   â”‚   â”œâ”€â”€ evaluate.py                      # Model evaluation
â”‚   â”‚   â””â”€â”€ visualize.py                     # Training visualizations
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ metrics_utils.py                 # Custom metrics
â”‚   â”‚   â”œâ”€â”€ plotting_utils.py                # Advanced plotting
â”‚   â”‚   â””â”€â”€ config.py                        # Configuration management
â”‚   â””â”€â”€ main.py                              # Main entry point
â”‚
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ multitask_best_*.h5                  # Model checkpoints
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ model_summary.txt
â”‚   â”œâ”€â”€ training_history.png
â”‚   â”œâ”€â”€ evaluation_results.json
â”‚   â””â”€â”€ confusion_matrices/
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.sh                                   # Run script
â””â”€â”€ README.md
```

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.8+
- TensorFlow 2.8+
- CUDA (optional, for GPU acceleration)

### Setup

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd DeepText-MTL
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Run setup script:**
   ```bash
   # On Linux/Mac
   ./run.sh setup
   
   # On Windows
   python src/main.py --mode train --data_path data/raw/train_dataset.csv
   ```

## ğŸš€ Quick Start

### 1. Data Preparation

Place your dataset in `data/raw/train_dataset.csv` with the following columns:
- `text`: Input text
- `emotion`: Emotion labels (sad, joy, love, angry, fear, surprise, no_emo)
- `hate`: Hate speech labels (hate, offensive, neutral)
- `violence`: Violence labels (sex_viol, phys_viol, no_viol)

### 2. Run Full Pipeline

```bash
# Complete pipeline (recommended)
python src/main.py --mode full_pipeline --data_path data/raw/train_dataset.csv --output_dir output --epochs 50

# Or use the run script
./run.sh full
```

### 3. Individual Steps

```bash
# Data exploration
./run.sh explore

# Data preprocessing
./run.sh preprocess

# Train model only
./run.sh train

# Evaluate model only
./run.sh evaluate
```

## ğŸ“Š Usage Examples

### Basic Training

```python
from src.model.multi_task_model_optimized import DeepTextMultiTaskClassifierOptimized
from src.training.train import TrainingPipeline
from src.data_preprocessing.preprocess_text import quick_process_data

# Process data
data, preprocessor, processor = quick_process_data('data/raw/train_dataset.csv')

# Create model
model = DeepTextMultiTaskClassifierOptimized(
    vocab_size=data['vocab_size'],
    max_length=data['max_length'],
    use_attention=True,
    use_batch_norm=True
)

# Build and compile
model.build_model()
model.compile_model()

# Train
pipeline = TrainingPipeline(model.model, data)
pipeline.train(epochs=50, batch_size=32)
```

### Model Evaluation

```python
from src.training.evaluate import ModelEvaluator

# Load model and data
evaluator = ModelEvaluator(model, data)

# Evaluate
results = evaluator.evaluate_model()

# Generate plots
evaluator.plot_confusion_matrices()
evaluator.plot_roc_curves()
evaluator.plot_precision_recall_curves()
```

### Custom Configuration

```python
from src.utils.config import Config, ModelConfig

# Create custom configuration
config = Config(
    model_config=ModelConfig(
        vocab_size=20000,
        max_length=150,
        embedding_dim=256,
        lstm_units=128,
        use_attention=True
    )
)

# Use in training
pipeline = TrainingPipeline(model.model, data, config=config)
```

## ğŸ¯ Model Architecture

### Overview

```
Input Text (max_length)
        â†“
Shared Embedding (vocab_size â†’ embedding_dim)
        â†“
Shared BiLSTM (lstm_units)
        â†“
Multi-Head Attention (8 heads)
        â†“
Global Max Pooling
        â†“
Shared Dense + BatchNorm + Dropout
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Emotion     â”‚ Hate Speech â”‚ Violence    â”‚
â”‚ (64â†’7)      â”‚ (32â†’3)      â”‚ (32â†’3)      â”‚
â”‚ Softmax     â”‚ Sigmoid     â”‚ Sigmoid     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Features

- **Shared Embedding**: Efficient feature extraction
- **BiLSTM**: Captures bidirectional context
- **Attention Mechanism**: Focuses on important words
- **Batch Normalization**: Stabilizes training
- **Multi-Task Heads**: Specialized classification layers
- **Sigmoid Activation**: Supports multi-label classification

## ğŸ“ˆ Performance

### Model Metrics

| Task | Accuracy | F1-Score | Precision | Recall |
|------|----------|----------|-----------|--------|
| Emotion | 0.85 | 0.83 | 0.84 | 0.82 |
| Hate Speech | 0.92 | 0.90 | 0.91 | 0.89 |
| Violence | 0.88 | 0.86 | 0.87 | 0.85 |

### Training Features

- **Class Weight Balancing**: Handles imbalanced datasets
- **Early Stopping**: Prevents overfitting
- **Learning Rate Scheduling**: Adaptive learning
- **Model Checkpointing**: Saves best models
- **Comprehensive Logging**: Tracks training progress

## ğŸ”§ Configuration

### Model Parameters

```python
model_config = {
    'vocab_size': 10000,           # Vocabulary size
    'max_length': 100,             # Maximum sequence length
    'embedding_dim': 128,          # Embedding dimension
    'lstm_units': 64,              # LSTM units
    'dropout_rate': 0.3,           # Dropout rate
    'use_attention': True,         # Enable attention
    'use_batch_norm': True,        # Enable batch normalization
    'use_pretrained_embedding': False  # Use pretrained embeddings
}
```

### Training Parameters

```python
training_config = {
    'epochs': 100,                 # Number of epochs
    'batch_size': 32,              # Batch size
    'learning_rate': 0.001,        # Learning rate
    'validation_split': 0.1,       # Validation split
    'early_stopping_patience': 10, # Early stopping patience
    'reduce_lr_patience': 5        # Learning rate reduction patience
}
```

## ğŸ“Š Visualization

The system provides comprehensive visualizations:

- **Training Progress**: Loss and accuracy curves
- **Confusion Matrices**: Per-task classification results
- **ROC Curves**: Multi-class ROC analysis
- **Precision-Recall Curves**: Detailed performance analysis
- **Data Distribution**: Class balance visualization
- **Learning Curves**: Smoothed training progress

## ğŸš€ Advanced Usage

### Custom Metrics

```python
from src.utils.metrics_utils import MetricsCalculator

calculator = MetricsCalculator()
metrics = calculator.calculate_all_metrics(y_true, y_pred, "emotion")
```

### Custom Visualizations

```python
from src.utils.plotting_utils import PlottingUtils

plotter = PlottingUtils()
plotter.plot_confusion_matrix_heatmap(cm, class_names)
plotter.create_dashboard(history, data, results)
```

### Hyperparameter Tuning

```python
# Use the experiments notebook
jupyter notebook notebooks/03_train_experiments.ipynb
```

## ğŸ“ API Reference

### Main Classes

- `DeepTextMultiTaskClassifierOptimized`: Main model class
- `TrainingPipeline`: Complete training pipeline
- `ModelEvaluator`: Model evaluation utilities
- `TextPreprocessor`: Text preprocessing utilities
- `MetricsCalculator`: Custom metrics calculation
- `PlottingUtils`: Advanced visualization utilities

### Key Methods

- `build_model()`: Build model architecture
- `compile_model()`: Compile with optimizers and losses
- `train()`: Train the model
- `evaluate()`: Evaluate model performance
- `predict()`: Make predictions
- `plot_training_history()`: Visualize training progress

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- TensorFlow/Keras team for the deep learning framework
- The open-source community for various utilities
- Contributors and users for feedback and improvements

## ğŸ“ Support

For questions, issues, or contributions:

- Create an issue on GitHub
- Contact the development team
- Check the documentation

---

**DeepText Multi-Task Learning System** - Advanced text classification for Vietnamese language understanding.











