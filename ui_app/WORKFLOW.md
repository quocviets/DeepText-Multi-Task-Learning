# Workflow: TÃ­ch há»£p UI/UX vá»›i Checkpoint Models

## ğŸ“‹ Tá»•ng quan

Workflow nÃ y mÃ´ táº£ cÃ¡ch tÃ­ch há»£p UI/UX vá»›i cÃ¡c checkpoint models cá»§a DeepText Multi-Task Learning project. Há»‡ thá»‘ng bao gá»“m:

1. **Model Service Layer** - Load vÃ  quáº£n lÃ½ models
2. **Streamlit UI Application** - Giao diá»‡n web tÆ°Æ¡ng tÃ¡c
3. **Integration Workflow** - Quy trÃ¬nh tÃ­ch há»£p

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Streamlit UI (app.py)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Single Input â”‚  â”‚ Batch Input  â”‚  â”‚ Visualizationâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      Model Service (model_service) â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
          â”‚  â”‚ Load Model from Checkpoint   â”‚  â”‚
          â”‚  â”‚ Load/Fit Tokenizer           â”‚  â”‚
          â”‚  â”‚ Preprocess Text               â”‚  â”‚
          â”‚  â”‚ Model Inference               â”‚  â”‚
          â”‚  â”‚ Post-process Predictions      â”‚  â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                             â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Model.h5   â”‚              â”‚ Training    â”‚
    â”‚ Checkpoint â”‚              â”‚ Data (CSV)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Workflow chi tiáº¿t

### BÆ°á»›c 1: Chuáº©n bá»‹ Dependencies

```bash
# CÃ i Ä‘áº·t requirements
pip install -r ui_app/requirements.txt
```

### BÆ°á»›c 2: Load Model tá»« Checkpoint

**Luá»“ng xá»­ lÃ½:**

1. **Khá»Ÿi táº¡o ModelService**
   ```python
   model_service = ModelService(
       model_path="DeepText-MTL/checkpoints/models/best_model_20251027_085402.h5",
       config_path="DeepText-MTL/config_default.json"
   )
   ```

2. **Load Config** (optional)
   - Äá»c config tá»« JSON
   - Cáº­p nháº­t parameters: vocab_size, max_length, classes

3. **Load Model**
   - Load `.h5` file vá»›i custom objects (Cast layer)
   - Verify model structure
   - Check input/output shapes

4. **Load Tokenizer**
   - Fit tokenizer tá»« training data
   - Hoáº·c load tokenizer Ä‘Ã£ Ä‘Æ°á»£c saved trÆ°á»›c Ä‘Ã³

### BÆ°á»›c 3: Preprocess Input Text

**Workflow preprocessing:**

```
Input Text
    â†“
Tokenizer.texts_to_sequences()  â†’  Convert to sequences
    â†“
pad_sequences()                  â†’  Padding/Truncating to max_len
    â†“
Numpy Array (batch_size, max_len) â†’ Ready for model input
```

**Code:**
```python
def preprocess_text(text: str) -> np.ndarray:
    sequences = self.tokenizer.texts_to_sequences([text])
    padded = pad_sequences(
        sequences,
        maxlen=self.max_len,
        padding='post',
        truncating='post'
    )
    return padded
```

### BÆ°á»›c 4: Model Inference

**Multi-task prediction:**

```
Input: (batch_size, max_len)
    â†“
Shared Embedding Layer
    â†“
Shared BiLSTM Layer
    â†“
Shared Dense Layer
    â†“
    â”œâ”€â”€â†’ Emotion Head (7 classes, softmax)
    â”œâ”€â”€â†’ Hate Head (3 classes, softmax)
    â””â”€â”€â†’ Violence Head (3 classes, softmax)
    â†“
Outputs: [emotion_probs, hate_probs, violence_probs]
```

**Code:**
```python
predictions = model.predict(X, verbose=0)
emotion_probs = predictions[0]    # (batch_size, 7)
hate_probs = predictions[1]      # (batch_size, 3)
violence_probs = predictions[2]  # (batch_size, 3)
```

### BÆ°á»›c 5: Post-process Predictions

**Xá»­ lÃ½ tá»«ng task:**

1. **Emotion** (Multi-class classification):
   ```python
   emotion_idx = np.argmax(emotion_probs, axis=1)
   emotion_label = emotion_classes[emotion_idx]
   confidence = emotion_probs[emotion_idx]
   ```

2. **Hate Speech** (Multi-label classification):
   ```python
   threshold = 0.5
   hate_labels = [
       hate_classes[i] 
       for i in range(len(hate_classes))
       if hate_probs[i] > threshold
   ]
   ```

3. **Violence** (Multi-label classification):
   ```python
   threshold = 0.5
   violence_labels = [
       violence_classes[i]
       for i in range(len(violence_classes))
       if violence_probs[i] > threshold
   ]
   ```

### BÆ°á»›c 6: Hiá»ƒn thá»‹ trong UI

**Streamlit UI workflow:**

1. **Single Prediction:**
   - User nháº­p text â†’ Click "PhÃ¢n tÃ­ch"
   - Hiá»ƒn thá»‹ 3 káº¿t quáº£ vá»›i metrics vÃ  charts
   - Interactive visualizations vá»›i Plotly

2. **Batch Prediction:**
   - Upload CSV hoáº·c nháº­p nhiá»u text
   - Process batch â†’ Display DataFrame
   - Export results to CSV

3. **Visualizations:**
   - Model information
   - Prediction probabilities charts
   - Combined multi-task visualization

---

## ğŸ“ Cáº¥u trÃºc Project

```
Last_Data/
â”œâ”€â”€ DeepText-MTL/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ best_model_20251027_085402.h5  â† Model checkpoint
â”‚   â”‚   â””â”€â”€ train_clean.csv                    â† Training data (cho tokenizer)
â”‚   â””â”€â”€ config_default.json                    â† Config file
â”‚
â””â”€â”€ ui_app/
    â”œâ”€â”€ app.py                 â† Streamlit UI application
    â”œâ”€â”€ model_service.py       â† Model service layer
    â”œâ”€â”€ requirements.txt       â† Dependencies
    â””â”€â”€ README.md              â† Documentation
```

---

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. Setup Environment

```bash
# Táº¡o virtual environment (optional)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
cd ui_app
pip install -r requirements.txt
```

### 2. Cháº¡y Application

```bash
# Cháº¡y Streamlit app
streamlit run app.py

# Hoáº·c vá»›i custom port
streamlit run app.py --server.port 8501
```

### 3. Sá»­ dá»¥ng UI

1. **Má»Ÿ browser:** http://localhost:8501

2. **Load Model tá»« Sidebar:**
   - Nháº­p Ä‘Æ°á»ng dáº«n model: `DeepText-MTL/checkpoints/models/best_model_20251027_085402.h5`
   - Nháº­p Ä‘Æ°á»ng dáº«n config: `DeepText-MTL/config_default.json`
   - Nháº­p Ä‘Æ°á»ng dáº«n training data: `DeepText-MTL/checkpoints/train_clean.csv`
   - Click "Load Model"

3. **Single Prediction:**
   - Tab "Single Prediction"
   - Nháº­p text vÃ o text area
   - Click "PhÃ¢n tÃ­ch"
   - Xem káº¿t quáº£ vá»›i visualizations

4. **Batch Prediction:**
   - Tab "Batch Prediction"
   - Upload CSV hoáº·c nháº­p nhiá»u text
   - Click "PhÃ¢n tÃ­ch Batch"
   - Download káº¿t quáº£ CSV

---

## ğŸ”§ Customization

### Thay Ä‘á»•i Model Path

Edit trong `app.py`:
```python
model_path = st.sidebar.text_input(
    "ÄÆ°á»ng dáº«n Model",
    value="your/path/to/model.h5"
)
```

### Thay Ä‘á»•i Thresholds

Edit trong `model_service.py`:
```python
self.hate_threshold = 0.5      # Threshold cho hate speech
self.violence_threshold = 0.5  # Threshold cho violence
```

### Thay Ä‘á»•i UI Theme

Edit trong `app.py`:
```python
st.set_page_config(
    page_title="Your Title",
    page_icon="ğŸ¯",
    layout="wide"
)
```

---

## ğŸ› Troubleshooting

### Lá»—i: Model file not found
- **NguyÃªn nhÃ¢n:** ÄÆ°á»ng dáº«n model khÃ´ng Ä‘Ãºng
- **Giáº£i phÃ¡p:** Kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n trong sidebar

### Lá»—i: Tokenizer chÆ°a Ä‘Æ°á»£c load
- **NguyÃªn nhÃ¢n:** Training data khÃ´ng tÃ¬m tháº¥y
- **Giáº£i phÃ¡p:** Cung cáº¥p Ä‘Æ°á»ng dáº«n Ä‘Ãºng Ä‘áº¿n `train_clean.csv`

### Lá»—i: Custom layer Cast
- **NguyÃªn nhÃ¢n:** Model cÃ³ custom layer cáº§n register
- **Giáº£i phÃ¡p:** ÄÃ£ Ä‘Æ°á»£c handle trong `model_service.py` vá»›i `@tf.keras.utils.register_keras_serializable()`

### Lá»—i: Memory issues vá»›i batch prediction
- **NguyÃªn nhÃ¢n:** Batch size quÃ¡ lá»›n
- **Giáº£i phÃ¡p:** Giáº£m batch size trong `predict_batch()` method

---

## ğŸ“Š Performance Optimization

### 1. Caching Model Loading
```python
@st.cache_resource
def load_model_cached(model_path):
    return get_model_service(model_path)
```

### 2. Batch Processing
- Sá»­ dá»¥ng `predict_batch()` thay vÃ¬ loop qua tá»«ng text
- Batch size optimize: 32-64

### 3. GPU Acceleration
- Ensure TensorFlow GPU Ä‘Æ°á»£c cÃ i Ä‘áº·t
- Model sáº½ tá»± Ä‘á»™ng sá»­ dá»¥ng GPU náº¿u available

---

## ğŸ” Security Considerations

1. **Input Validation:**
   - Validate text length
   - Sanitize user input
   - Rate limiting cho API calls

2. **Model Protection:**
   - KhÃ´ng expose model files trá»±c tiáº¿p
   - Sá»­ dá»¥ng authentication náº¿u deploy production

3. **Error Handling:**
   - Graceful error messages
   - KhÃ´ng expose internal errors

---

## ğŸš¢ Deployment

### Option 1: Streamlit Cloud
```bash
# Push code lÃªn GitHub
# Deploy trÃªn streamlit.io
```

### Option 2: Docker
```dockerfile
FROM python:3.9

WORKDIR /app
COPY ui_app/requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD ["streamlit", "run", "app.py", "--server.port=8501"]
```

### Option 3: Local Server
```bash
# Cháº¡y vá»›i production mode
streamlit run app.py --server.port 8501 --server.address 0.0.0.0
```

---

## ğŸ“ Next Steps

1. âœ… TÃ­ch há»£p vá»›i checkpoint models
2. âœ… Táº¡o UI/UX vá»›i Streamlit
3. âœ… Batch prediction support
4. âœ… Visualization vá»›i Plotly
5. ğŸ”„ Add authentication
6. ğŸ”„ Add logging & monitoring
7. ğŸ”„ Export model metrics
8. ğŸ”„ A/B testing support

---

## ğŸ“š References

- [DeepText-MTL Model Architecture](../DeepText-MTL/src/model/deeptext_multitask.py)
- [Streamlit Documentation](https://docs.streamlit.io)
- [TensorFlow/Keras](https://www.tensorflow.org/api_docs/python/tf/keras)

