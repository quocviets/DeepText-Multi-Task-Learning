"""
Streamlit UI Application - DeepText Multi-Task Learning Demo
Giao di·ªán web ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi model t·ª´ checkpoint
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import sys
import os

# Th√™m path ƒë·ªÉ import model_service
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from model_service import get_model_service, ModelService

# Page config
st.set_page_config(
    page_title="DeepText Multi-Task Learning",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS - Modern & Beautiful UI
st.markdown("""
<style>
    /* Import Google Fonts */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap');
    
    /* Global Styles */
    * {
        font-family: 'Inter', sans-serif;
    }
    
    /* Main Header */
    .main-header {
        font-size: 3rem;
        font-weight: 800;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        text-align: center;
        margin-bottom: 0.5rem;
        letter-spacing: -0.02em;
    }
    
    .sub-header {
        font-size: 1.3rem;
        color: #64748b;
        text-align: center;
        margin-bottom: 2.5rem;
        font-weight: 400;
    }
    
    /* Sidebar Styling */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8fafc 0%, #f1f5f9 100%);
    }
    
    /* Cards & Boxes */
    .prediction-box {
        background: linear-gradient(135deg, #ffffff 0%, #f8fafc 100%);
        padding: 1.5rem;
        border-radius: 1rem;
        margin: 1rem 0;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
        border: 1px solid #e2e8f0;
    }
    
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 0.75rem;
        box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06);
        margin: 0.5rem 0;
        border: 1px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .metric-card:hover {
        box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        transform: translateY(-2px);
    }
    
    /* Buttons */
    .stButton > button {
        border-radius: 0.5rem;
        font-weight: 600;
        transition: all 0.3s ease;
        border: none;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1);
    }
    
    /* Tabs */
    .stTabs [data-baseweb="tab-list"] {
        gap: 0.5rem;
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 0.5rem 0.5rem 0 0;
        padding: 0.75rem 1.5rem;
        font-weight: 600;
    }
    
    /* Text Input */
    .stTextInput > div > div > input {
        border-radius: 0.5rem;
        border: 2px solid #e2e8f0;
        transition: all 0.3s ease;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    /* Text Area */
    .stTextArea > div > div > textarea {
        border-radius: 0.5rem;
        border: 2px solid #e2e8f0;
    }
    
    /* Success/Error Messages */
    .stAlert {
        border-radius: 0.75rem;
        border-left: 4px solid;
    }
    
    /* Metrics */
    [data-testid="stMetricValue"] {
        font-size: 2rem;
        font-weight: 700;
    }
    
    [data-testid="stMetricLabel"] {
        font-size: 0.9rem;
        font-weight: 500;
        color: #64748b;
    }
    
    /* Sidebar */
    .css-1d391kg {
        padding: 1.5rem;
    }
    
    /* Main Container */
    .main .block-container {
        padding-top: 3rem;
        padding-bottom: 3rem;
    }
    
    /* Hide Streamlit Branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* Custom Scrollbar */
    ::-webkit-scrollbar {
        width: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: #f1f5f9;
    }
    
    ::-webkit-scrollbar-thumb {
        background: #cbd5e1;
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: #94a3b8;
    }
    
    /* Animation */
    @keyframes fadeIn {
        from {
            opacity: 0;
            transform: translateY(10px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    .fade-in {
        animation: fadeIn 0.5s ease-in;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'model_service' not in st.session_state:
    st.session_state.model_service = None
if 'auto_load_attempted' not in st.session_state:
    st.session_state.auto_load_attempted = False

def auto_load_model():
    """T·ª± ƒë·ªông load model khi app kh·ªüi ƒë·ªông"""
    if st.session_state.model_loaded or st.session_state.auto_load_attempted:
        return
    
    # ƒê∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh (t·ª´ root c·ªßa repo tr√™n Streamlit Cloud)
    default_paths = {
        'model': [
            'checkpoints/models/best_model_20251027_085402.h5',
            'DeepText-MTL/checkpoints/models/best_model_20251027_085402.h5',
        ],
        'config': [
            'config_default.json',
            'DeepText-MTL/config_default.json',
        ],
        'train_data': [
            'checkpoints/train_clean.csv',
            'DeepText-MTL/checkpoints/train_clean.csv',
        ]
    }
    
    # T√¨m ƒë∆∞·ªùng d·∫´n t·ªìn t·∫°i
    model_path = None
    config_path = None
    train_data_path = None
    
    for path in default_paths['model']:
        if os.path.exists(path):
            model_path = path
            break
    
    for path in default_paths['config']:
        if os.path.exists(path):
            config_path = path
            break
    
    for path in default_paths['train_data']:
        if os.path.exists(path):
            train_data_path = path
            break
    
    # N·∫øu t√¨m th·∫•y ƒë·ªß model v√† training data, t·ª± ƒë·ªông load
    if model_path and train_data_path:
        try:
            with st.spinner("üîÑ ƒêang t·ª± ƒë·ªông load model... Vui l√≤ng ƒë·ª£i..."):
                st.session_state.model_service = get_model_service(
                    model_path=model_path,
                    config_path=config_path,
                    train_data_path=train_data_path
                )
                st.session_state.model_loaded = True
                st.session_state.auto_load_attempted = True
                st.rerun()
        except Exception as e:
            st.session_state.auto_load_attempted = True
            # Kh√¥ng hi·ªÉn th·ªã l·ªói, ƒë·ªÉ user t·ª± load n·∫øu c·∫ßn
    
def load_model():
    """Load model v√†o session state"""
    # ƒê∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh (t·ª± ƒë·ªông detect)
    default_model_paths = [
        'checkpoints/models/best_model_20251027_085402.h5',
        'DeepText-MTL/checkpoints/models/best_model_20251027_085402.h5'
    ]
    
    default_config_paths = [
        'config_default.json',
        'DeepText-MTL/config_default.json'
    ]
    
    default_train_paths = [
        'checkpoints/train_clean.csv',
        'DeepText-MTL/checkpoints/train_clean.csv'
    ]
    
    # T√¨m ƒë∆∞·ªùng d·∫´n t·ªìn t·∫°i
    default_model = next((p for p in default_model_paths if os.path.exists(p)), default_model_paths[0])
    default_config = next((p for p in default_config_paths if os.path.exists(p)), default_config_paths[0])
    default_train = next((p for p in default_train_paths if os.path.exists(p)), default_train_paths[0])
    
    model_path = st.sidebar.text_input(
        "ƒê∆∞·ªùng d·∫´n Model",
        value=default_model
    )
    
    config_path = st.sidebar.text_input(
        "ƒê∆∞·ªùng d·∫´n Config (optional)",
        value=default_config
    )
    
    train_data_path = st.sidebar.text_input(
        "ƒê∆∞·ªùng d·∫´n Training Data (ƒë·ªÉ fit tokenizer)",
        value=default_train
    )
    
    if st.sidebar.button("üîÑ Load Model", type="primary"):
        # Validate model path
        if not model_path or not model_path.strip():
            st.sidebar.error("‚ùå Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n model!")
            return
        
        if not os.path.exists(model_path):
            st.sidebar.error(f"‚ùå File model kh√¥ng t·ªìn t·∫°i: {model_path}")
            st.sidebar.info("üí° Ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n ho·∫∑c s·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi")
            return
        
        # Validate config path (optional)
        if config_path and config_path.strip() and not os.path.exists(config_path):
            st.sidebar.warning(f"‚ö†Ô∏è File config kh√¥ng t·ªìn t·∫°i: {config_path}")
            st.sidebar.info("üí° S·∫Ω ti·∫øp t·ª•c kh√¥ng d√πng config")
            config_path = None
        
        # Validate training data path
        if not train_data_path or not train_data_path.strip():
            st.sidebar.error("‚ùå Training data path l√† b·∫Øt bu·ªôc ƒë·ªÉ fit tokenizer!")
            st.sidebar.info("üí° Tokenizer c·∫ßn ƒë∆∞·ª£c fit t·ª´ training data ƒë·ªÉ vocabulary kh·ªõp v·ªõi model")
            return
        elif not os.path.exists(train_data_path):
            st.sidebar.error(f"‚ùå File training data kh√¥ng t·ªìn t·∫°i: {train_data_path}")
            st.sidebar.info("üí° Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n ho·∫∑c s·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi")
            return
        
        # Load model
        try:
            with st.spinner("ƒêang load model... Vui l√≤ng ƒë·ª£i..."):
                st.session_state.model_service = get_model_service(
                    model_path=model_path,
                    config_path=config_path,
                    train_data_path=train_data_path
                )
                st.session_state.model_loaded = True
                st.sidebar.success("‚úÖ Model ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng!")
                st.rerun()
                
        except Exception as e:
            st.sidebar.error(f"‚ùå L·ªói khi load model: {str(e)}")
            st.session_state.model_loaded = False
            st.session_state.model_service = None

def main():
    """Main application"""
    
    # T·ª± ƒë·ªông load model khi kh·ªüi ƒë·ªông (n·∫øu ch∆∞a load)
    auto_load_model()
    
    # Beautiful Header v·ªõi gradient
    st.markdown("""
    <div style="text-align: center; padding: 2rem 0;">
        <h1 class="main-header">ü§ñ DeepText Multi-Task Learning</h1>
        <p class="sub-header">Ph√¢n t√≠ch c·∫£m x√∫c, ph√°t hi·ªán ng√¥n t·ª´ th√π ƒë·ªãch v√† b·∫°o l·ª±c</p>
        <div style="display: flex; justify-content: center; gap: 1rem; margin-top: 1rem;">
            <span style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 0.5rem 1.5rem; border-radius: 2rem; font-size: 0.9rem; font-weight: 600;">üé≠ Emotion</span>
            <span style="background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); color: white; padding: 0.5rem 1.5rem; border-radius: 2rem; font-size: 0.9rem; font-weight: 600;">üò° Hate Speech</span>
            <span style="background: linear-gradient(135deg, #fa709a 0%, #fee140 100%); color: white; padding: 0.5rem 1.5rem; border-radius: 2rem; font-size: 0.9rem; font-weight: 600;">‚öîÔ∏è Violence</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è C·∫•u h√¨nh")
        
        # Hi·ªÉn th·ªã th√¥ng tin n·∫øu ƒë√£ auto-load
        if st.session_state.model_loaded and st.session_state.auto_load_attempted:
            st.success("‚úÖ Model ƒë√£ t·ª± ƒë·ªông load!")
            st.caption("üí° N·∫øu c·∫ßn load model kh√°c, click Reset v√† nh·∫≠p ƒë∆∞·ªùng d·∫´n m·ªõi")
        else:
            load_model()
        
        if st.session_state.model_loaded:
            st.markdown("---")
            st.success("‚úÖ Model ƒë√£ s·∫µn s√†ng")
            
            # Model info
            if st.button("‚ÑπÔ∏è Th√¥ng tin Model"):
                info = st.session_state.model_service.get_model_info()
                st.json(info)
            
            # Reset button
            if st.button("üîÑ Reset Model", type="secondary"):
                st.session_state.model_loaded = False
                st.session_state.model_service = None
                # Reset singleton
                from ui_app.model_service import reset_model_service
                reset_model_service()
                st.rerun()
    
    # Main content
    if not st.session_state.model_loaded:
        st.warning("‚ö†Ô∏è Vui l√≤ng load model t·ª´ sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu s·ª≠ d·ª•ng.")
        st.info("""
        **H∆∞·ªõng d·∫´n:**
        1. Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn file model (.h5) trong sidebar
        2. Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn file config (optional)
        3. Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn training data ƒë·ªÉ fit tokenizer
        4. Click "Load Model" ƒë·ªÉ kh·ªüi t·∫°o
        """)
        return
    
    # Tabs
    tab1, tab2, tab3, tab4 = st.tabs(["üìù Single Prediction", "üìä Batch Prediction", "üìà Visualizations", "‚ÑπÔ∏è About"])
    
    with tab1:
        st.header("Ph√¢n t√≠ch Text ƒë∆°n l·∫ª")
        
        # Input text
        text_input = st.text_area(
            "Nh·∫≠p text c·∫ßn ph√¢n t√≠ch:",
            height=150,
            placeholder="V√≠ d·ª•: T√¥i c·∫£m th·∫•y r·∫•t vui v·∫ª v√† h·∫°nh ph√∫c h√¥m nay!"
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            predict_button = st.button("üîç Ph√¢n t√≠ch", type="primary", use_container_width=True)
        
        if predict_button and text_input.strip():
            with st.spinner("ƒêang x·ª≠ l√Ω..."):
                try:
                    prediction = st.session_state.model_service.predict(text_input.strip())
                    
                    # Display results
                    st.markdown("---")
                    st.subheader("üìä K·∫øt qu·∫£ ph√¢n t√≠ch")
                    
                    # Emotion
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.markdown("### üé≠ C·∫£m x√∫c")
                        emotion_label = prediction['emotion']['label']
                        emotion_conf = prediction['emotion']['confidence']
                        
                        # Map emotion to emoji
                        emotion_emoji = {
                            'sad': 'üò¢',
                            'joy': 'üòä',
                            'love': '‚ù§Ô∏è',
                            'angry': 'üò†',
                            'fear': 'üò®',
                            'surprise': 'üò≤',
                            'no_emo': 'üòê'
                        }
                        
                        emoji = emotion_emoji.get(emotion_label, 'üòê')
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 1.5rem; border-radius: 1rem; margin-bottom: 1rem; color: white;">
                            <div style="font-size: 2.5rem; margin-bottom: 0.5rem;">{emoji}</div>
                            <div style="font-size: 1.2rem; font-weight: 600;">{emotion_label.capitalize()}</div>
                            <div style="font-size: 0.9rem; opacity: 0.9; margin-top: 0.5rem;">ƒê·ªô tin c·∫≠y: {emotion_conf:.1%}</div>
                        </div>
                        """, unsafe_allow_html=True)
                        
                    # Emotion probabilities chart v·ªõi gradient ƒë·∫πp
                    emotion_df = pd.DataFrame({
                        'Emotion': list(prediction['emotion']['probabilities'].keys()),
                        'Probability': list(prediction['emotion']['probabilities'].values())
                    })
                    fig_emotion = px.bar(
                        emotion_df,
                        x='Emotion',
                        y='Probability',
                        title='üìä Ph√¢n b·ªë C·∫£m x√∫c',
                        color='Probability',
                        color_continuous_scale=px.colors.sequential.Purples,
                        text='Probability'
                    )
                    fig_emotion.update_traces(
                        texttemplate='%{text:.1%}',
                        textposition='outside',
                        marker=dict(
                            line=dict(color='rgba(0,0,0,0.1)', width=1),
                            cornerradius=8
                        )
                    )
                    fig_emotion.update_layout(
                        height=350,
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)',
                        font=dict(family="Inter", size=12),
                        title_font=dict(size=18, color='#1e293b'),
                        xaxis=dict(title='', tickfont=dict(size=11)),
                        yaxis=dict(title='X√°c su·∫•t', tickformat='.0%')
                    )
                    st.plotly_chart(fig_emotion, use_container_width=True)
                    
                    with col2:
                        st.markdown("### üò° Ng√¥n t·ª´ th√π ƒë·ªãch")
                        hate_labels = prediction['hate']['labels']
                        hate_confidences = prediction['hate']['confidences']
                        
                        if hate_labels:
                            for label in hate_labels:
                                conf = hate_confidences[label]
                                st.metric(
                                    label.capitalize(),
                                    f"{conf:.2%}"
                                )
                        else:
                            st.success("‚úÖ Kh√¥ng ph√°t hi·ªán ng√¥n t·ª´ th√π ƒë·ªãch")
                        
                        # Hate probabilities chart v·ªõi gradient ƒë·∫πp
                        hate_df = pd.DataFrame({
                            'Category': list(prediction['hate']['probabilities'].keys()),
                            'Probability': list(prediction['hate']['probabilities'].values())
                        })
                        fig_hate = px.bar(
                            hate_df,
                            x='Category',
                            y='Probability',
                            title='üìä Ph√¢n b·ªë Ng√¥n t·ª´ th√π ƒë·ªãch',
                            color='Probability',
                            color_continuous_scale=px.colors.sequential.Reds,
                            text='Probability'
                        )
                        fig_hate.update_traces(
                            texttemplate='%{text:.1%}',
                            textposition='outside',
                            marker=dict(
                                line=dict(color='rgba(0,0,0,0.1)', width=1),
                                cornerradius=8
                            )
                        )
                        fig_hate.update_layout(
                            height=350,
                            plot_bgcolor='rgba(0,0,0,0)',
                            paper_bgcolor='rgba(0,0,0,0)',
                            font=dict(family="Inter", size=12),
                            title_font=dict(size=18, color='#1e293b'),
                            xaxis=dict(title='', tickfont=dict(size=11)),
                            yaxis=dict(title='X√°c su·∫•t', tickformat='.0%')
                        )
                        st.plotly_chart(fig_hate, use_container_width=True)
                    
                    with col3:
                        st.markdown("### ‚öîÔ∏è B·∫°o l·ª±c")
                        violence_labels = prediction['violence']['labels']
                        violence_confidences = prediction['violence']['confidences']
                        
                        if violence_labels:
                            for label in violence_labels:
                                conf = violence_confidences[label]
                                st.metric(
                                    label.capitalize(),
                                    f"{conf:.2%}"
                                )
                        else:
                            st.success("‚úÖ Kh√¥ng ph√°t hi·ªán n·ªôi dung b·∫°o l·ª±c")
                        
                        # Violence probabilities chart v·ªõi gradient ƒë·∫πp
                        violence_df = pd.DataFrame({
                            'Category': list(prediction['violence']['probabilities'].keys()),
                            'Probability': list(prediction['violence']['probabilities'].values())
                        })
                        fig_violence = px.bar(
                            violence_df,
                            x='Category',
                            y='Probability',
                            title='üìä Ph√¢n b·ªë B·∫°o l·ª±c',
                            color='Probability',
                            color_continuous_scale=px.colors.sequential.Oranges,
                            text='Probability'
                        )
                        fig_violence.update_traces(
                            texttemplate='%{text:.1%}',
                            textposition='outside',
                            marker=dict(
                                line=dict(color='rgba(0,0,0,0.1)', width=1),
                                cornerradius=8
                            )
                        )
                        fig_violence.update_layout(
                            height=350,
                            plot_bgcolor='rgba(0,0,0,0)',
                            paper_bgcolor='rgba(0,0,0,0)',
                            font=dict(family="Inter", size=12),
                            title_font=dict(size=18, color='#1e293b'),
                            xaxis=dict(title='', tickfont=dict(size=11)),
                            yaxis=dict(title='X√°c su·∫•t', tickformat='.0%')
                        )
                        st.plotly_chart(fig_violence, use_container_width=True)
                    
                    # Combined visualization v·ªõi gradient ƒë·∫πp
                    st.markdown("---")
                    st.markdown("""
                    <div style="text-align: center; margin: 2rem 0;">
                        <h2 style="font-size: 1.8rem; font-weight: 700; color: #1e293b; margin-bottom: 1rem;">üìà T·ªïng quan Predictions</h2>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Create combined chart v·ªõi m√†u gradient ƒë·∫πp
                    fig_combined = make_subplots(
                        rows=1, cols=3,
                        subplot_titles=('üé≠ C·∫£m x√∫c', 'üò° Ng√¥n t·ª´ th√π ƒë·ªãch', '‚öîÔ∏è B·∫°o l·ª±c'),
                        specs=[[{"type": "bar"}, {"type": "bar"}, {"type": "bar"}]],
                        horizontal_spacing=0.1
                    )
                    
                    # Emotion v·ªõi gradient purple
                    emotion_colors = px.colors.sequential.Purples
                    fig_combined.add_trace(
                        go.Bar(
                            x=list(prediction['emotion']['probabilities'].keys()),
                            y=list(prediction['emotion']['probabilities'].values()),
                            name='C·∫£m x√∫c',
                            marker=dict(
                                color=list(prediction['emotion']['probabilities'].values()),
                                colorscale='Purples',
                                line=dict(color='rgba(0,0,0,0.1)', width=1),
                                cornerradius=8
                            ),
                            text=[f"{v:.1%}" for v in prediction['emotion']['probabilities'].values()],
                            textposition='outside'
                        ),
                        row=1, col=1
                    )
                    
                    # Hate v·ªõi gradient red
                    fig_combined.add_trace(
                        go.Bar(
                            x=list(prediction['hate']['probabilities'].keys()),
                            y=list(prediction['hate']['probabilities'].values()),
                            name='Ng√¥n t·ª´ th√π ƒë·ªãch',
                            marker=dict(
                                color=list(prediction['hate']['probabilities'].values()),
                                colorscale='Reds',
                                line=dict(color='rgba(0,0,0,0.1)', width=1),
                                cornerradius=8
                            ),
                            text=[f"{v:.1%}" for v in prediction['hate']['probabilities'].values()],
                            textposition='outside'
                        ),
                        row=1, col=2
                    )
                    
                    # Violence v·ªõi gradient orange
                    fig_combined.add_trace(
                        go.Bar(
                            x=list(prediction['violence']['probabilities'].keys()),
                            y=list(prediction['violence']['probabilities'].values()),
                            name='B·∫°o l·ª±c',
                            marker=dict(
                                color=list(prediction['violence']['probabilities'].values()),
                                colorscale='Oranges',
                                line=dict(color='rgba(0,0,0,0.1)', width=1),
                                cornerradius=8
                            ),
                            text=[f"{v:.1%}" for v in prediction['violence']['probabilities'].values()],
                            textposition='outside'
                        ),
                        row=1, col=3
                    )
                    
                    fig_combined.update_layout(
                        height=450,
                        showlegend=False,
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)',
                        font=dict(family="Inter", size=11),
                        title_font=dict(size=20, color='#1e293b'),
                        margin=dict(l=20, r=20, t=60, b=40)
                    )
                    
                    # Update x-axis labels
                    for i in range(1, 4):
                        fig_combined.update_xaxes(tickangle=-45, row=1, col=i)
                        fig_combined.update_yaxes(tickformat='.0%', row=1, col=i)
                    
                    st.plotly_chart(fig_combined, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi predict: {str(e)}")
        elif predict_button:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p text ƒë·ªÉ ph√¢n t√≠ch")
    
    with tab2:
        st.header("Ph√¢n t√≠ch Batch (nhi·ªÅu text)")
        
        # Option 1: Upload CSV
        uploaded_file = st.file_uploader(
            "Upload file CSV (c·ªôt 'text' ch·ª©a c√°c text c·∫ßn ph√¢n t√≠ch)",
            type=['csv']
        )
        
        # Option 2: Input multiple texts
        st.markdown("**Ho·∫∑c nh·∫≠p nhi·ªÅu text:**")
        batch_texts = st.text_area(
            "Nh·∫≠p nhi·ªÅu text (m·ªói d√≤ng m·ªôt text):",
            height=200,
            placeholder="Text 1\nText 2\nText 3\n..."
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            batch_predict_button = st.button("üîç Ph√¢n t√≠ch Batch", type="primary", use_container_width=True)
        
        if batch_predict_button:
            texts_to_process = []
            
            if uploaded_file is not None:
                try:
                    df = pd.read_csv(uploaded_file)
                    if 'text' in df.columns:
                        texts_to_process = df['text'].astype(str).tolist()
                    else:
                        st.error("‚ùå File CSV ph·∫£i c√≥ c·ªôt 'text'")
                        return
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")
                    return
            elif batch_texts.strip():
                texts_to_process = [t.strip() for t in batch_texts.split('\n') if t.strip()]
            else:
                st.warning("‚ö†Ô∏è Vui l√≤ng upload file ho·∫∑c nh·∫≠p text")
                return
            
            if texts_to_process:
                with st.spinner(f"ƒêang x·ª≠ l√Ω {len(texts_to_process)} texts..."):
                    try:
                        results = st.session_state.model_service.predict_batch(texts_to_process)
                        
                        # Create results DataFrame
                        results_data = []
                        for r in results:
                            results_data.append({
                                'Text': r['text'],
                                'Emotion': r['emotion']['label'],
                                'Emotion Confidence': f"{r['emotion']['confidence']:.2%}",
                                'Hate Labels': ', '.join(r['hate']['labels']) if r['hate']['labels'] else 'None',
                                'Violence Labels': ', '.join(r['violence']['labels']) if r['violence']['labels'] else 'None'
                            })
                        
                        results_df = pd.DataFrame(results_data)
                        
                        st.success(f"‚úÖ ƒê√£ ph√¢n t√≠ch {len(results)} texts")
                        st.dataframe(results_df, use_container_width=True)
                        
                        # Download button
                        csv = results_df.to_csv(index=False).encode('utf-8-sig')
                        st.download_button(
                            label="üì• Download k·∫øt qu·∫£ CSV",
                            data=csv,
                            file_name="predictions_batch.csv",
                            mime="text/csv"
                        )
                        
                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi predict batch: {str(e)}")
    
    with tab3:
        st.header("Visualizations & Analytics")
        
        if st.session_state.model_loaded and st.session_state.model_service:
            try:
                model_info = st.session_state.model_service.get_model_info()
                
                st.subheader("üìä Model Information")
                st.json(model_info)
                
                st.subheader("üìà Task Configuration")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown("**üé≠ Emotion Classes**")
                    emotion_classes = model_info.get('emotion_classes', ['sad', 'joy', 'love', 'angry', 'fear', 'surprise', 'no_emo'])
                    for i, cls in enumerate(emotion_classes, 1):
                        st.write(f"{i}. {cls}")
                
                with col2:
                    st.markdown("**üò° Hate Classes**")
                    hate_classes = model_info.get('hate_classes', ['hate', 'offensive', 'neutral'])
                    for i, cls in enumerate(hate_classes, 1):
                        st.write(f"{i}. {cls}")
                
                with col3:
                    st.markdown("**‚öîÔ∏è Violence Classes**")
                    violence_classes = model_info.get('violence_classes', ['sex_viol', 'phys_viol', 'no_viol'])
                    for i, cls in enumerate(violence_classes, 1):
                        st.write(f"{i}. {cls}")
            except Exception as e:
                st.error(f"‚ùå L·ªói khi l·∫•y th√¥ng tin model: {str(e)}")
                st.info("üí° Vui l√≤ng th·ª≠ load l·∫°i model")
        else:
            st.info("Vui l√≤ng load model ƒë·ªÉ xem th√¥ng tin")
    
    with tab4:
        st.header("‚ÑπÔ∏è About")
        
        st.markdown("""
        ## DeepText Multi-Task Learning
        
        ·ª®ng d·ª•ng n√†y t√≠ch h·ª£p v·ªõi checkpoint models c·ªßa DeepText Multi-Task Learning model ƒë·ªÉ:
        
        ### üéØ Ch·ª©c nƒÉng ch√≠nh:
        
        1. **üé≠ Ph√¢n t√≠ch c·∫£m x√∫c** (7 classes)
           - Sad, Joy, Love, Angry, Fear, Surprise, No Emotion
        
        2. **üò° Ph√°t hi·ªán ng√¥n t·ª´ th√π ƒë·ªãch** (3 classes)
           - Hate, Offensive, Neutral
        
        3. **‚öîÔ∏è Ph√°t hi·ªán b·∫°o l·ª±c** (3 classes)
           - Sexual Violence, Physical Violence, No Violence
        
        ### üìã Workflow:
        
        1. **Load Model**: Load model t·ª´ checkpoint (.h5 file)
        2. **Load Tokenizer**: Fit tokenizer t·ª´ training data
        3. **Preprocess**: Convert text th√†nh sequences v√† padding
        4. **Predict**: Model inference v·ªõi 3 outputs
        5. **Post-process**: Interpret predictions v√† hi·ªÉn th·ªã k·∫øt qu·∫£
        
        ### üîß Technical Stack:
        
        - **Backend**: TensorFlow/Keras
        - **Frontend**: Streamlit
        - **Visualization**: Plotly
        - **Data Processing**: Pandas, NumPy
        
        ### üìñ Usage:
        
        1. Ch·∫°y app: `streamlit run app.py`
        2. Load model t·ª´ sidebar
        3. Nh·∫≠p text v√† nh·∫≠n predictions
        4. Xem visualizations v√† export k·∫øt qu·∫£
        
        ### üöÄ Features:
        
        - ‚úÖ Single text prediction
        - ‚úÖ Batch prediction t·ª´ CSV
        - ‚úÖ Interactive visualizations
        - ‚úÖ Export results
        - ‚úÖ Model information display
        """)

if __name__ == "__main__":
    main()

