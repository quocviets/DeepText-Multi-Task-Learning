"""
Streamlit UI Application - DeepText Multi-Task Learning Demo
Giao diá»‡n web Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i model tá»« checkpoint
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import sys
import os

# ThÃªm path Ä‘á»ƒ import model_service
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from model_service import get_model_service, ModelService

# Page config
st.set_page_config(
    page_title="DeepText Multi-Task Learning",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .prediction-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    .stAlert {
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'model_service' not in st.session_state:
    st.session_state.model_service = None
if 'auto_load_attempted' not in st.session_state:
    st.session_state.auto_load_attempted = False

def auto_load_model():
    """Tá»± Ä‘á»™ng load model khi app khá»Ÿi Ä‘á»™ng"""
    if st.session_state.model_loaded or st.session_state.auto_load_attempted:
        return
    
    # ÄÆ°á»ng dáº«n máº·c Ä‘á»‹nh (tá»« root cá»§a repo trÃªn Streamlit Cloud)
    default_paths = {
        'model': [
            'checkpoints/models/best_model_20251027_085402.h5',
            'DeepText-MTL/checkpoints/models/best_model_20251027_085402.h5',
        ],
        'config': [
            'config_default.json',
            'DeepText-MTL/config_default.json',
        ],
        'train_data': [
            'checkpoints/train_clean.csv',
            'DeepText-MTL/checkpoints/train_clean.csv',
        ]
    }
    
    # TÃ¬m Ä‘Æ°á»ng dáº«n tá»“n táº¡i
    model_path = None
    config_path = None
    train_data_path = None
    
    for path in default_paths['model']:
        if os.path.exists(path):
            model_path = path
            break
    
    for path in default_paths['config']:
        if os.path.exists(path):
            config_path = path
            break
    
    for path in default_paths['train_data']:
        if os.path.exists(path):
            train_data_path = path
            break
    
    # Náº¿u tÃ¬m tháº¥y Ä‘á»§ model vÃ  training data, tá»± Ä‘á»™ng load
    if model_path and train_data_path:
        try:
            with st.spinner("ğŸ”„ Äang tá»± Ä‘á»™ng load model... Vui lÃ²ng Ä‘á»£i..."):
                st.session_state.model_service = get_model_service(
                    model_path=model_path,
                    config_path=config_path,
                    train_data_path=train_data_path
                )
                st.session_state.model_loaded = True
                st.session_state.auto_load_attempted = True
                st.rerun()
        except Exception as e:
            st.session_state.auto_load_attempted = True
            # KhÃ´ng hiá»ƒn thá»‹ lá»—i, Ä‘á»ƒ user tá»± load náº¿u cáº§n
    
def load_model():
    """Load model vÃ o session state"""
    # ÄÆ°á»ng dáº«n máº·c Ä‘á»‹nh (tá»± Ä‘á»™ng detect)
    default_model_paths = [
        'checkpoints/models/best_model_20251027_085402.h5',
        'DeepText-MTL/checkpoints/models/best_model_20251027_085402.h5'
    ]
    
    default_config_paths = [
        'config_default.json',
        'DeepText-MTL/config_default.json'
    ]
    
    default_train_paths = [
        'checkpoints/train_clean.csv',
        'DeepText-MTL/checkpoints/train_clean.csv'
    ]
    
    # TÃ¬m Ä‘Æ°á»ng dáº«n tá»“n táº¡i
    default_model = next((p for p in default_model_paths if os.path.exists(p)), default_model_paths[0])
    default_config = next((p for p in default_config_paths if os.path.exists(p)), default_config_paths[0])
    default_train = next((p for p in default_train_paths if os.path.exists(p)), default_train_paths[0])
    
    model_path = st.sidebar.text_input(
        "ÄÆ°á»ng dáº«n Model",
        value=default_model
    )
    
    config_path = st.sidebar.text_input(
        "ÄÆ°á»ng dáº«n Config (optional)",
        value=default_config
    )
    
    train_data_path = st.sidebar.text_input(
        "ÄÆ°á»ng dáº«n Training Data (Ä‘á»ƒ fit tokenizer)",
        value=default_train
    )
    
    if st.sidebar.button("ğŸ”„ Load Model", type="primary"):
        # Validate model path
        if not model_path or not model_path.strip():
            st.sidebar.error("âŒ Vui lÃ²ng nháº­p Ä‘Æ°á»ng dáº«n model!")
            return
        
        if not os.path.exists(model_path):
            st.sidebar.error(f"âŒ File model khÃ´ng tá»“n táº¡i: {model_path}")
            st.sidebar.info("ğŸ’¡ Kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n hoáº·c sá»­ dá»¥ng Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i")
            return
        
        # Validate config path (optional)
        if config_path and config_path.strip() and not os.path.exists(config_path):
            st.sidebar.warning(f"âš ï¸ File config khÃ´ng tá»“n táº¡i: {config_path}")
            st.sidebar.info("ğŸ’¡ Sáº½ tiáº¿p tá»¥c khÃ´ng dÃ¹ng config")
            config_path = None
        
        # Validate training data path
        if not train_data_path or not train_data_path.strip():
            st.sidebar.error("âŒ Training data path lÃ  báº¯t buá»™c Ä‘á»ƒ fit tokenizer!")
            st.sidebar.info("ğŸ’¡ Tokenizer cáº§n Ä‘Æ°á»£c fit tá»« training data Ä‘á»ƒ vocabulary khá»›p vá»›i model")
            return
        elif not os.path.exists(train_data_path):
            st.sidebar.error(f"âŒ File training data khÃ´ng tá»“n táº¡i: {train_data_path}")
            st.sidebar.info("ğŸ’¡ Vui lÃ²ng kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n hoáº·c sá»­ dá»¥ng Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i")
            return
        
        # Load model
        try:
            with st.spinner("Äang load model... Vui lÃ²ng Ä‘á»£i..."):
                st.session_state.model_service = get_model_service(
                    model_path=model_path,
                    config_path=config_path,
                    train_data_path=train_data_path
                )
                st.session_state.model_loaded = True
                st.sidebar.success("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c load thÃ nh cÃ´ng!")
                st.rerun()
                
        except Exception as e:
            st.sidebar.error(f"âŒ Lá»—i khi load model: {str(e)}")
            st.session_state.model_loaded = False
            st.session_state.model_service = None

def main():
    """Main application"""
    
    # Tá»± Ä‘á»™ng load model khi khá»Ÿi Ä‘á»™ng (náº¿u chÆ°a load)
    auto_load_model()
    
    # Header
    st.markdown('<h1 class="main-header">ğŸ¤– DeepText Multi-Task Learning</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">PhÃ¢n tÃ­ch cáº£m xÃºc, phÃ¡t hiá»‡n ngÃ´n tá»« thÃ¹ Ä‘á»‹ch vÃ  báº¡o lá»±c</p>', unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ Cáº¥u hÃ¬nh")
        
        # Hiá»ƒn thá»‹ thÃ´ng tin náº¿u Ä‘Ã£ auto-load
        if st.session_state.model_loaded and st.session_state.auto_load_attempted:
            st.success("âœ… Model Ä‘Ã£ tá»± Ä‘á»™ng load!")
            st.caption("ğŸ’¡ Náº¿u cáº§n load model khÃ¡c, click Reset vÃ  nháº­p Ä‘Æ°á»ng dáº«n má»›i")
        else:
            load_model()
        
        if st.session_state.model_loaded:
            st.markdown("---")
            st.success("âœ… Model Ä‘Ã£ sáºµn sÃ ng")
            
            # Model info
            if st.button("â„¹ï¸ ThÃ´ng tin Model"):
                info = st.session_state.model_service.get_model_info()
                st.json(info)
            
            # Reset button
            if st.button("ğŸ”„ Reset Model", type="secondary"):
                st.session_state.model_loaded = False
                st.session_state.model_service = None
                # Reset singleton
                from ui_app.model_service import reset_model_service
                reset_model_service()
                st.rerun()
    
    # Main content
    if not st.session_state.model_loaded:
        st.warning("âš ï¸ Vui lÃ²ng load model tá»« sidebar Ä‘á»ƒ báº¯t Ä‘áº§u sá»­ dá»¥ng.")
        st.info("""
        **HÆ°á»›ng dáº«n:**
        1. Nháº­p Ä‘Æ°á»ng dáº«n Ä‘áº¿n file model (.h5) trong sidebar
        2. Nháº­p Ä‘Æ°á»ng dáº«n Ä‘áº¿n file config (optional)
        3. Nháº­p Ä‘Æ°á»ng dáº«n Ä‘áº¿n training data Ä‘á»ƒ fit tokenizer
        4. Click "Load Model" Ä‘á»ƒ khá»Ÿi táº¡o
        """)
        return
    
    # Tabs
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ Single Prediction", "ğŸ“Š Batch Prediction", "ğŸ“ˆ Visualizations", "â„¹ï¸ About"])
    
    with tab1:
        st.header("PhÃ¢n tÃ­ch Text Ä‘Æ¡n láº»")
        
        # Input text
        text_input = st.text_area(
            "Nháº­p text cáº§n phÃ¢n tÃ­ch:",
            height=150,
            placeholder="VÃ­ dá»¥: TÃ´i cáº£m tháº¥y ráº¥t vui váº» vÃ  háº¡nh phÃºc hÃ´m nay!"
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            predict_button = st.button("ğŸ” PhÃ¢n tÃ­ch", type="primary", use_container_width=True)
        
        if predict_button and text_input.strip():
            with st.spinner("Äang xá»­ lÃ½..."):
                try:
                    prediction = st.session_state.model_service.predict(text_input.strip())
                    
                    # Display results
                    st.markdown("---")
                    st.subheader("ğŸ“Š Káº¿t quáº£ phÃ¢n tÃ­ch")
                    
                    # Emotion
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.markdown("### ğŸ­ Cáº£m xÃºc")
                        emotion_label = prediction['emotion']['label']
                        emotion_conf = prediction['emotion']['confidence']
                        
                        # Map emotion to emoji
                        emotion_emoji = {
                            'sad': 'ğŸ˜¢',
                            'joy': 'ğŸ˜Š',
                            'love': 'â¤ï¸',
                            'angry': 'ğŸ˜ ',
                            'fear': 'ğŸ˜¨',
                            'surprise': 'ğŸ˜²',
                            'no_emo': 'ğŸ˜'
                        }
                        
                        emoji = emotion_emoji.get(emotion_label, 'ğŸ˜')
                        st.metric(
                            "NhÃ£n",
                            f"{emoji} {emotion_label.capitalize()}"
                        )
                        st.metric(
                            "Äá»™ tin cáº­y",
                            f"{emotion_conf:.2%}"
                        )
                        
                        # Emotion probabilities chart
                        emotion_df = pd.DataFrame({
                            'Emotion': list(prediction['emotion']['probabilities'].keys()),
                            'Probability': list(prediction['emotion']['probabilities'].values())
                        })
                        fig_emotion = px.bar(
                            emotion_df,
                            x='Emotion',
                            y='Probability',
                            title='PhÃ¢n bá»‘ Cáº£m xÃºc',
                            color='Probability',
                            color_continuous_scale='Blues'
                        )
                        fig_emotion.update_layout(height=300)
                        st.plotly_chart(fig_emotion, use_container_width=True)
                    
                    with col2:
                        st.markdown("### ğŸ˜¡ NgÃ´n tá»« thÃ¹ Ä‘á»‹ch")
                        hate_labels = prediction['hate']['labels']
                        hate_confidences = prediction['hate']['confidences']
                        
                        if hate_labels:
                            for label in hate_labels:
                                conf = hate_confidences[label]
                                st.metric(
                                    label.capitalize(),
                                    f"{conf:.2%}"
                                )
                        else:
                            st.success("âœ… KhÃ´ng phÃ¡t hiá»‡n ngÃ´n tá»« thÃ¹ Ä‘á»‹ch")
                        
                        # Hate probabilities chart
                        hate_df = pd.DataFrame({
                            'Category': list(prediction['hate']['probabilities'].keys()),
                            'Probability': list(prediction['hate']['probabilities'].values())
                        })
                        fig_hate = px.bar(
                            hate_df,
                            x='Category',
                            y='Probability',
                            title='PhÃ¢n bá»‘ NgÃ´n tá»« thÃ¹ Ä‘á»‹ch',
                            color='Probability',
                            color_continuous_scale='Reds'
                        )
                        fig_hate.update_layout(height=300)
                        st.plotly_chart(fig_hate, use_container_width=True)
                    
                    with col3:
                        st.markdown("### âš”ï¸ Báº¡o lá»±c")
                        violence_labels = prediction['violence']['labels']
                        violence_confidences = prediction['violence']['confidences']
                        
                        if violence_labels:
                            for label in violence_labels:
                                conf = violence_confidences[label]
                                st.metric(
                                    label.capitalize(),
                                    f"{conf:.2%}"
                                )
                        else:
                            st.success("âœ… KhÃ´ng phÃ¡t hiá»‡n ná»™i dung báº¡o lá»±c")
                        
                        # Violence probabilities chart
                        violence_df = pd.DataFrame({
                            'Category': list(prediction['violence']['probabilities'].keys()),
                            'Probability': list(prediction['violence']['probabilities'].values())
                        })
                        fig_violence = px.bar(
                            violence_df,
                            x='Category',
                            y='Probability',
                            title='PhÃ¢n bá»‘ Báº¡o lá»±c',
                            color='Probability',
                            color_continuous_scale='Oranges'
                        )
                        fig_violence.update_layout(height=300)
                        st.plotly_chart(fig_violence, use_container_width=True)
                    
                    # Combined visualization
                    st.markdown("---")
                    st.subheader("ğŸ“ˆ Tá»•ng quan Predictions")
                    
                    # Create combined chart
                    fig_combined = make_subplots(
                        rows=1, cols=3,
                        subplot_titles=('Cáº£m xÃºc', 'NgÃ´n tá»« thÃ¹ Ä‘á»‹ch', 'Báº¡o lá»±c'),
                        specs=[[{"type": "bar"}, {"type": "bar"}, {"type": "bar"}]]
                    )
                    
                    # Emotion
                    fig_combined.add_trace(
                        go.Bar(
                            x=list(prediction['emotion']['probabilities'].keys()),
                            y=list(prediction['emotion']['probabilities'].values()),
                            name='Cáº£m xÃºc',
                            marker_color='blue'
                        ),
                        row=1, col=1
                    )
                    
                    # Hate
                    fig_combined.add_trace(
                        go.Bar(
                            x=list(prediction['hate']['probabilities'].keys()),
                            y=list(prediction['hate']['probabilities'].values()),
                            name='NgÃ´n tá»« thÃ¹ Ä‘á»‹ch',
                            marker_color='red'
                        ),
                        row=1, col=2
                    )
                    
                    # Violence
                    fig_combined.add_trace(
                        go.Bar(
                            x=list(prediction['violence']['probabilities'].keys()),
                            y=list(prediction['violence']['probabilities'].values()),
                            name='Báº¡o lá»±c',
                            marker_color='orange'
                        ),
                        row=1, col=3
                    )
                    
                    fig_combined.update_layout(
                        height=400,
                        showlegend=False,
                        title_text="PhÃ¢n tÃ­ch Multi-Task"
                    )
                    st.plotly_chart(fig_combined, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"âŒ Lá»—i khi predict: {str(e)}")
        elif predict_button:
            st.warning("âš ï¸ Vui lÃ²ng nháº­p text Ä‘á»ƒ phÃ¢n tÃ­ch")
    
    with tab2:
        st.header("PhÃ¢n tÃ­ch Batch (nhiá»u text)")
        
        # Option 1: Upload CSV
        uploaded_file = st.file_uploader(
            "Upload file CSV (cá»™t 'text' chá»©a cÃ¡c text cáº§n phÃ¢n tÃ­ch)",
            type=['csv']
        )
        
        # Option 2: Input multiple texts
        st.markdown("**Hoáº·c nháº­p nhiá»u text:**")
        batch_texts = st.text_area(
            "Nháº­p nhiá»u text (má»—i dÃ²ng má»™t text):",
            height=200,
            placeholder="Text 1\nText 2\nText 3\n..."
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            batch_predict_button = st.button("ğŸ” PhÃ¢n tÃ­ch Batch", type="primary", use_container_width=True)
        
        if batch_predict_button:
            texts_to_process = []
            
            if uploaded_file is not None:
                try:
                    df = pd.read_csv(uploaded_file)
                    if 'text' in df.columns:
                        texts_to_process = df['text'].astype(str).tolist()
                    else:
                        st.error("âŒ File CSV pháº£i cÃ³ cá»™t 'text'")
                        return
                except Exception as e:
                    st.error(f"âŒ Lá»—i khi Ä‘á»c file: {str(e)}")
                    return
            elif batch_texts.strip():
                texts_to_process = [t.strip() for t in batch_texts.split('\n') if t.strip()]
            else:
                st.warning("âš ï¸ Vui lÃ²ng upload file hoáº·c nháº­p text")
                return
            
            if texts_to_process:
                with st.spinner(f"Äang xá»­ lÃ½ {len(texts_to_process)} texts..."):
                    try:
                        results = st.session_state.model_service.predict_batch(texts_to_process)
                        
                        # Create results DataFrame
                        results_data = []
                        for r in results:
                            results_data.append({
                                'Text': r['text'],
                                'Emotion': r['emotion']['label'],
                                'Emotion Confidence': f"{r['emotion']['confidence']:.2%}",
                                'Hate Labels': ', '.join(r['hate']['labels']) if r['hate']['labels'] else 'None',
                                'Violence Labels': ', '.join(r['violence']['labels']) if r['violence']['labels'] else 'None'
                            })
                        
                        results_df = pd.DataFrame(results_data)
                        
                        st.success(f"âœ… ÄÃ£ phÃ¢n tÃ­ch {len(results)} texts")
                        st.dataframe(results_df, use_container_width=True)
                        
                        # Download button
                        csv = results_df.to_csv(index=False).encode('utf-8-sig')
                        st.download_button(
                            label="ğŸ“¥ Download káº¿t quáº£ CSV",
                            data=csv,
                            file_name="predictions_batch.csv",
                            mime="text/csv"
                        )
                        
                    except Exception as e:
                        st.error(f"âŒ Lá»—i khi predict batch: {str(e)}")
    
    with tab3:
        st.header("Visualizations & Analytics")
        
        if st.session_state.model_loaded:
            model_info = st.session_state.model_service.get_model_info()
            
            st.subheader("ğŸ“Š Model Information")
            st.json(model_info)
            
            st.subheader("ğŸ“ˆ Task Configuration")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("**ğŸ­ Emotion Classes**")
                for i, cls in enumerate(model_info['emotion_classes'], 1):
                    st.write(f"{i}. {cls}")
            
            with col2:
                st.markdown("**ğŸ˜¡ Hate Classes**")
                for i, cls in enumerate(model_info['hate_classes'], 1):
                    st.write(f"{i}. {cls}")
            
            with col3:
                st.markdown("**âš”ï¸ Violence Classes**")
                for i, cls in enumerate(model_info['violence_classes'], 1):
                    st.write(f"{i}. {cls}")
        else:
            st.info("Vui lÃ²ng load model Ä‘á»ƒ xem thÃ´ng tin")
    
    with tab4:
        st.header("â„¹ï¸ About")
        
        st.markdown("""
        ## DeepText Multi-Task Learning
        
        á»¨ng dá»¥ng nÃ y tÃ­ch há»£p vá»›i checkpoint models cá»§a DeepText Multi-Task Learning model Ä‘á»ƒ:
        
        ### ğŸ¯ Chá»©c nÄƒng chÃ­nh:
        
        1. **ğŸ­ PhÃ¢n tÃ­ch cáº£m xÃºc** (7 classes)
           - Sad, Joy, Love, Angry, Fear, Surprise, No Emotion
        
        2. **ğŸ˜¡ PhÃ¡t hiá»‡n ngÃ´n tá»« thÃ¹ Ä‘á»‹ch** (3 classes)
           - Hate, Offensive, Neutral
        
        3. **âš”ï¸ PhÃ¡t hiá»‡n báº¡o lá»±c** (3 classes)
           - Sexual Violence, Physical Violence, No Violence
        
        ### ğŸ“‹ Workflow:
        
        1. **Load Model**: Load model tá»« checkpoint (.h5 file)
        2. **Load Tokenizer**: Fit tokenizer tá»« training data
        3. **Preprocess**: Convert text thÃ nh sequences vÃ  padding
        4. **Predict**: Model inference vá»›i 3 outputs
        5. **Post-process**: Interpret predictions vÃ  hiá»ƒn thá»‹ káº¿t quáº£
        
        ### ğŸ”§ Technical Stack:
        
        - **Backend**: TensorFlow/Keras
        - **Frontend**: Streamlit
        - **Visualization**: Plotly
        - **Data Processing**: Pandas, NumPy
        
        ### ğŸ“– Usage:
        
        1. Cháº¡y app: `streamlit run app.py`
        2. Load model tá»« sidebar
        3. Nháº­p text vÃ  nháº­n predictions
        4. Xem visualizations vÃ  export káº¿t quáº£
        
        ### ğŸš€ Features:
        
        - âœ… Single text prediction
        - âœ… Batch prediction tá»« CSV
        - âœ… Interactive visualizations
        - âœ… Export results
        - âœ… Model information display
        """)

if __name__ == "__main__":
    main()

