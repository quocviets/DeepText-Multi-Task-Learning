"""
Streamlit UI Application - DeepText Multi-Task Learning Demo
Giao di·ªán web ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi model t·ª´ checkpoint
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import sys
import os

# Th√™m path ƒë·ªÉ import model_service
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from model_service import get_model_service, ModelService

# Page config
st.set_page_config(
    page_title="DeepText Multi-Task Learning",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .prediction-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    .stAlert {
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'model_loaded' not in st.session_state:
    st.session_state.model_loaded = False
if 'model_service' not in st.session_state:
    st.session_state.model_service = None

def load_model():
    """Load model v√†o session state"""
    model_path = st.sidebar.text_input(
        "ƒê∆∞·ªùng d·∫´n Model",
        value="DeepText-MTL/checkpoints/models/best_model_20251027_085402.h5"
    )
    
    config_path = st.sidebar.text_input(
        "ƒê∆∞·ªùng d·∫´n Config (optional)",
        value="DeepText-MTL/config_default.json"
    )
    
    train_data_path = st.sidebar.text_input(
        "ƒê∆∞·ªùng d·∫´n Training Data (ƒë·ªÉ fit tokenizer)",
        value="DeepText-MTL/checkpoints/train_clean.csv"
    )
    
    if st.sidebar.button("üîÑ Load Model", type="primary"):
        # Validate model path
        if not model_path or not model_path.strip():
            st.sidebar.error("‚ùå Vui l√≤ng nh·∫≠p ƒë∆∞·ªùng d·∫´n model!")
            return
        
        if not os.path.exists(model_path):
            st.sidebar.error(f"‚ùå File model kh√¥ng t·ªìn t·∫°i: {model_path}")
            st.sidebar.info("üí° Ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n ho·∫∑c s·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi")
            return
        
        # Validate config path (optional)
        if config_path and config_path.strip() and not os.path.exists(config_path):
            st.sidebar.warning(f"‚ö†Ô∏è File config kh√¥ng t·ªìn t·∫°i: {config_path}")
            st.sidebar.info("üí° S·∫Ω ti·∫øp t·ª•c kh√¥ng d√πng config")
            config_path = None
        
        # Validate training data path
        if not train_data_path or not train_data_path.strip():
            st.sidebar.error("‚ùå Training data path l√† b·∫Øt bu·ªôc ƒë·ªÉ fit tokenizer!")
            st.sidebar.info("üí° Tokenizer c·∫ßn ƒë∆∞·ª£c fit t·ª´ training data ƒë·ªÉ vocabulary kh·ªõp v·ªõi model")
            return
        elif not os.path.exists(train_data_path):
            st.sidebar.error(f"‚ùå File training data kh√¥ng t·ªìn t·∫°i: {train_data_path}")
            st.sidebar.info("üí° Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n ho·∫∑c s·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi")
            return
        
        # Load model
        try:
            with st.spinner("ƒêang load model... Vui l√≤ng ƒë·ª£i..."):
                st.session_state.model_service = get_model_service(
                    model_path=model_path,
                    config_path=config_path,
                    train_data_path=train_data_path
                )
                st.session_state.model_loaded = True
                st.sidebar.success("‚úÖ Model ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng!")
                st.rerun()
                
        except Exception as e:
            st.sidebar.error(f"‚ùå L·ªói khi load model: {str(e)}")
            st.session_state.model_loaded = False
            st.session_state.model_service = None

def main():
    """Main application"""
    
    # Header
    st.markdown('<h1 class="main-header">ü§ñ DeepText Multi-Task Learning</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Ph√¢n t√≠ch c·∫£m x√∫c, ph√°t hi·ªán ng√¥n t·ª´ th√π ƒë·ªãch v√† b·∫°o l·ª±c</p>', unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è C·∫•u h√¨nh")
        load_model()
        
        if st.session_state.model_loaded:
            st.markdown("---")
            st.success("‚úÖ Model ƒë√£ s·∫µn s√†ng")
            
            # Model info
            if st.button("‚ÑπÔ∏è Th√¥ng tin Model"):
                info = st.session_state.model_service.get_model_info()
                st.json(info)
            
            # Reset button
            if st.button("üîÑ Reset Model", type="secondary"):
                st.session_state.model_loaded = False
                st.session_state.model_service = None
                # Reset singleton
                from ui_app.model_service import reset_model_service
                reset_model_service()
                st.rerun()
    
    # Main content
    if not st.session_state.model_loaded:
        st.warning("‚ö†Ô∏è Vui l√≤ng load model t·ª´ sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu s·ª≠ d·ª•ng.")
        st.info("""
        **H∆∞·ªõng d·∫´n:**
        1. Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn file model (.h5) trong sidebar
        2. Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn file config (optional)
        3. Nh·∫≠p ƒë∆∞·ªùng d·∫´n ƒë·∫øn training data ƒë·ªÉ fit tokenizer
        4. Click "Load Model" ƒë·ªÉ kh·ªüi t·∫°o
        """)
        return
    
    # Tabs
    tab1, tab2, tab3, tab4 = st.tabs(["üìù Single Prediction", "üìä Batch Prediction", "üìà Visualizations", "‚ÑπÔ∏è About"])
    
    with tab1:
        st.header("Ph√¢n t√≠ch Text ƒë∆°n l·∫ª")
        
        # Input text
        text_input = st.text_area(
            "Nh·∫≠p text c·∫ßn ph√¢n t√≠ch:",
            height=150,
            placeholder="V√≠ d·ª•: T√¥i c·∫£m th·∫•y r·∫•t vui v·∫ª v√† h·∫°nh ph√∫c h√¥m nay!"
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            predict_button = st.button("üîç Ph√¢n t√≠ch", type="primary", use_container_width=True)
        
        if predict_button and text_input.strip():
            with st.spinner("ƒêang x·ª≠ l√Ω..."):
                try:
                    prediction = st.session_state.model_service.predict(text_input.strip())
                    
                    # Display results
                    st.markdown("---")
                    st.subheader("üìä K·∫øt qu·∫£ ph√¢n t√≠ch")
                    
                    # Emotion
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.markdown("### üé≠ C·∫£m x√∫c")
                        emotion_label = prediction['emotion']['label']
                        emotion_conf = prediction['emotion']['confidence']
                        
                        # Map emotion to emoji
                        emotion_emoji = {
                            'sad': 'üò¢',
                            'joy': 'üòä',
                            'love': '‚ù§Ô∏è',
                            'angry': 'üò†',
                            'fear': 'üò®',
                            'surprise': 'üò≤',
                            'no_emo': 'üòê'
                        }
                        
                        emoji = emotion_emoji.get(emotion_label, 'üòê')
                        st.metric(
                            "Nh√£n",
                            f"{emoji} {emotion_label.capitalize()}"
                        )
                        st.metric(
                            "ƒê·ªô tin c·∫≠y",
                            f"{emotion_conf:.2%}"
                        )
                        
                        # Emotion probabilities chart
                        emotion_df = pd.DataFrame({
                            'Emotion': list(prediction['emotion']['probabilities'].keys()),
                            'Probability': list(prediction['emotion']['probabilities'].values())
                        })
                        fig_emotion = px.bar(
                            emotion_df,
                            x='Emotion',
                            y='Probability',
                            title='Ph√¢n b·ªë C·∫£m x√∫c',
                            color='Probability',
                            color_continuous_scale='Blues'
                        )
                        fig_emotion.update_layout(height=300)
                        st.plotly_chart(fig_emotion, use_container_width=True)
                    
                    with col2:
                        st.markdown("### üò° Ng√¥n t·ª´ th√π ƒë·ªãch")
                        hate_labels = prediction['hate']['labels']
                        hate_confidences = prediction['hate']['confidences']
                        
                        if hate_labels:
                            for label in hate_labels:
                                conf = hate_confidences[label]
                                st.metric(
                                    label.capitalize(),
                                    f"{conf:.2%}"
                                )
                        else:
                            st.success("‚úÖ Kh√¥ng ph√°t hi·ªán ng√¥n t·ª´ th√π ƒë·ªãch")
                        
                        # Hate probabilities chart
                        hate_df = pd.DataFrame({
                            'Category': list(prediction['hate']['probabilities'].keys()),
                            'Probability': list(prediction['hate']['probabilities'].values())
                        })
                        fig_hate = px.bar(
                            hate_df,
                            x='Category',
                            y='Probability',
                            title='Ph√¢n b·ªë Ng√¥n t·ª´ th√π ƒë·ªãch',
                            color='Probability',
                            color_continuous_scale='Reds'
                        )
                        fig_hate.update_layout(height=300)
                        st.plotly_chart(fig_hate, use_container_width=True)
                    
                    with col3:
                        st.markdown("### ‚öîÔ∏è B·∫°o l·ª±c")
                        violence_labels = prediction['violence']['labels']
                        violence_confidences = prediction['violence']['confidences']
                        
                        if violence_labels:
                            for label in violence_labels:
                                conf = violence_confidences[label]
                                st.metric(
                                    label.capitalize(),
                                    f"{conf:.2%}"
                                )
                        else:
                            st.success("‚úÖ Kh√¥ng ph√°t hi·ªán n·ªôi dung b·∫°o l·ª±c")
                        
                        # Violence probabilities chart
                        violence_df = pd.DataFrame({
                            'Category': list(prediction['violence']['probabilities'].keys()),
                            'Probability': list(prediction['violence']['probabilities'].values())
                        })
                        fig_violence = px.bar(
                            violence_df,
                            x='Category',
                            y='Probability',
                            title='Ph√¢n b·ªë B·∫°o l·ª±c',
                            color='Probability',
                            color_continuous_scale='Oranges'
                        )
                        fig_violence.update_layout(height=300)
                        st.plotly_chart(fig_violence, use_container_width=True)
                    
                    # Combined visualization
                    st.markdown("---")
                    st.subheader("üìà T·ªïng quan Predictions")
                    
                    # Create combined chart
                    fig_combined = make_subplots(
                        rows=1, cols=3,
                        subplot_titles=('C·∫£m x√∫c', 'Ng√¥n t·ª´ th√π ƒë·ªãch', 'B·∫°o l·ª±c'),
                        specs=[[{"type": "bar"}, {"type": "bar"}, {"type": "bar"}]]
                    )
                    
                    # Emotion
                    fig_combined.add_trace(
                        go.Bar(
                            x=list(prediction['emotion']['probabilities'].keys()),
                            y=list(prediction['emotion']['probabilities'].values()),
                            name='C·∫£m x√∫c',
                            marker_color='blue'
                        ),
                        row=1, col=1
                    )
                    
                    # Hate
                    fig_combined.add_trace(
                        go.Bar(
                            x=list(prediction['hate']['probabilities'].keys()),
                            y=list(prediction['hate']['probabilities'].values()),
                            name='Ng√¥n t·ª´ th√π ƒë·ªãch',
                            marker_color='red'
                        ),
                        row=1, col=2
                    )
                    
                    # Violence
                    fig_combined.add_trace(
                        go.Bar(
                            x=list(prediction['violence']['probabilities'].keys()),
                            y=list(prediction['violence']['probabilities'].values()),
                            name='B·∫°o l·ª±c',
                            marker_color='orange'
                        ),
                        row=1, col=3
                    )
                    
                    fig_combined.update_layout(
                        height=400,
                        showlegend=False,
                        title_text="Ph√¢n t√≠ch Multi-Task"
                    )
                    st.plotly_chart(fig_combined, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi predict: {str(e)}")
        elif predict_button:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p text ƒë·ªÉ ph√¢n t√≠ch")
    
    with tab2:
        st.header("Ph√¢n t√≠ch Batch (nhi·ªÅu text)")
        
        # Option 1: Upload CSV
        uploaded_file = st.file_uploader(
            "Upload file CSV (c·ªôt 'text' ch·ª©a c√°c text c·∫ßn ph√¢n t√≠ch)",
            type=['csv']
        )
        
        # Option 2: Input multiple texts
        st.markdown("**Ho·∫∑c nh·∫≠p nhi·ªÅu text:**")
        batch_texts = st.text_area(
            "Nh·∫≠p nhi·ªÅu text (m·ªói d√≤ng m·ªôt text):",
            height=200,
            placeholder="Text 1\nText 2\nText 3\n..."
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
            batch_predict_button = st.button("üîç Ph√¢n t√≠ch Batch", type="primary", use_container_width=True)
        
        if batch_predict_button:
            texts_to_process = []
            
            if uploaded_file is not None:
                try:
                    df = pd.read_csv(uploaded_file)
                    if 'text' in df.columns:
                        texts_to_process = df['text'].astype(str).tolist()
                    else:
                        st.error("‚ùå File CSV ph·∫£i c√≥ c·ªôt 'text'")
                        return
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")
                    return
            elif batch_texts.strip():
                texts_to_process = [t.strip() for t in batch_texts.split('\n') if t.strip()]
            else:
                st.warning("‚ö†Ô∏è Vui l√≤ng upload file ho·∫∑c nh·∫≠p text")
                return
            
            if texts_to_process:
                with st.spinner(f"ƒêang x·ª≠ l√Ω {len(texts_to_process)} texts..."):
                    try:
                        results = st.session_state.model_service.predict_batch(texts_to_process)
                        
                        # Create results DataFrame
                        results_data = []
                        for r in results:
                            results_data.append({
                                'Text': r['text'],
                                'Emotion': r['emotion']['label'],
                                'Emotion Confidence': f"{r['emotion']['confidence']:.2%}",
                                'Hate Labels': ', '.join(r['hate']['labels']) if r['hate']['labels'] else 'None',
                                'Violence Labels': ', '.join(r['violence']['labels']) if r['violence']['labels'] else 'None'
                            })
                        
                        results_df = pd.DataFrame(results_data)
                        
                        st.success(f"‚úÖ ƒê√£ ph√¢n t√≠ch {len(results)} texts")
                        st.dataframe(results_df, use_container_width=True)
                        
                        # Download button
                        csv = results_df.to_csv(index=False).encode('utf-8-sig')
                        st.download_button(
                            label="üì• Download k·∫øt qu·∫£ CSV",
                            data=csv,
                            file_name="predictions_batch.csv",
                            mime="text/csv"
                        )
                        
                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi predict batch: {str(e)}")
    
    with tab3:
        st.header("Visualizations & Analytics")
        
        if st.session_state.model_loaded:
            model_info = st.session_state.model_service.get_model_info()
            
            st.subheader("üìä Model Information")
            st.json(model_info)
            
            st.subheader("üìà Task Configuration")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("**üé≠ Emotion Classes**")
                for i, cls in enumerate(model_info['emotion_classes'], 1):
                    st.write(f"{i}. {cls}")
            
            with col2:
                st.markdown("**üò° Hate Classes**")
                for i, cls in enumerate(model_info['hate_classes'], 1):
                    st.write(f"{i}. {cls}")
            
            with col3:
                st.markdown("**‚öîÔ∏è Violence Classes**")
                for i, cls in enumerate(model_info['violence_classes'], 1):
                    st.write(f"{i}. {cls}")
        else:
            st.info("Vui l√≤ng load model ƒë·ªÉ xem th√¥ng tin")
    
    with tab4:
        st.header("‚ÑπÔ∏è About")
        
        st.markdown("""
        ## DeepText Multi-Task Learning
        
        ·ª®ng d·ª•ng n√†y t√≠ch h·ª£p v·ªõi checkpoint models c·ªßa DeepText Multi-Task Learning model ƒë·ªÉ:
        
        ### üéØ Ch·ª©c nƒÉng ch√≠nh:
        
        1. **üé≠ Ph√¢n t√≠ch c·∫£m x√∫c** (7 classes)
           - Sad, Joy, Love, Angry, Fear, Surprise, No Emotion
        
        2. **üò° Ph√°t hi·ªán ng√¥n t·ª´ th√π ƒë·ªãch** (3 classes)
           - Hate, Offensive, Neutral
        
        3. **‚öîÔ∏è Ph√°t hi·ªán b·∫°o l·ª±c** (3 classes)
           - Sexual Violence, Physical Violence, No Violence
        
        ### üìã Workflow:
        
        1. **Load Model**: Load model t·ª´ checkpoint (.h5 file)
        2. **Load Tokenizer**: Fit tokenizer t·ª´ training data
        3. **Preprocess**: Convert text th√†nh sequences v√† padding
        4. **Predict**: Model inference v·ªõi 3 outputs
        5. **Post-process**: Interpret predictions v√† hi·ªÉn th·ªã k·∫øt qu·∫£
        
        ### üîß Technical Stack:
        
        - **Backend**: TensorFlow/Keras
        - **Frontend**: Streamlit
        - **Visualization**: Plotly
        - **Data Processing**: Pandas, NumPy
        
        ### üìñ Usage:
        
        1. Ch·∫°y app: `streamlit run app.py`
        2. Load model t·ª´ sidebar
        3. Nh·∫≠p text v√† nh·∫≠n predictions
        4. Xem visualizations v√† export k·∫øt qu·∫£
        
        ### üöÄ Features:
        
        - ‚úÖ Single text prediction
        - ‚úÖ Batch prediction t·ª´ CSV
        - ‚úÖ Interactive visualizations
        - ‚úÖ Export results
        - ‚úÖ Model information display
        """)

if __name__ == "__main__":
    main()

